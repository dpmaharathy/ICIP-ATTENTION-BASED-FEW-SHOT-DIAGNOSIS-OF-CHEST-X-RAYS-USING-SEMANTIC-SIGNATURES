Time to load train arrays
(array(['Cardiomegaly', 'Consolidation', 'Fracture', 'Lung Lesion',
       'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pneumothorax'],
      dtype='<U16'), array([1539, 1034, 1377,  782, 7000, 7000, 3572, 2274]))
Time to load train arrays
(array(['Atelectasis', 'Edema', 'Enlarged Cardiomediastinum'], dtype='<U26'), array([1716, 3080, 1028]))
Time to load train arrays
(array(['Pleural Other', 'Pneumonia', 'Support Devices'], dtype='<U15'), array([ 291,  423, 5303]))
Model:  1
Epoch 1 Train -- Loss: 0.1106 Acc: 0.1555
Val Results -- Loss: 0.2696 Acc: 0.3907


Epoch 2 Train -- Loss: 0.1083 Acc: 0.1809
Prev Val Results -- Loss: 0.2696 Acc: 0.3907
0.012528246581554381
Val Results -- Loss: 0.2570 Acc: 0.3956


Epoch 3 Train -- Loss: 0.1080 Acc: 0.1906
Prev Val Results -- Loss: 0.2570 Acc: 0.3956
3.487753868097743e-05
Val Results -- Loss: 0.2571 Acc: 0.4224


Epoch 4 Train -- Loss: 0.1077 Acc: 0.1977
Prev Val Results -- Loss: 0.2571 Acc: 0.4224
0.00666131982207302
Val Results -- Loss: 0.2637 Acc: 0.4095


Epoch 5 Train -- Loss: 0.1075 Acc: 0.2047
Prev Val Results -- Loss: 0.2637 Acc: 0.4095
0.013099996060133012
Val Results -- Loss: 0.2506 Acc: 0.4368


Epoch 6 Train -- Loss: 0.1071 Acc: 0.2085
Prev Val Results -- Loss: 0.2506 Acc: 0.4368
0.005826079368591308
Val Results -- Loss: 0.2564 Acc: 0.4460


Epoch 7 Train -- Loss: 0.1068 Acc: 0.2163
Prev Val Results -- Loss: 0.2564 Acc: 0.4460
0.005498420506715784
Val Results -- Loss: 0.2619 Acc: 0.4265


Model:  2
Epoch 1 Train -- Loss: 0.1098 Acc: 0.1575
Val Results -- Loss: 0.2553 Acc: 0.3892


Epoch 2 Train -- Loss: 0.1083 Acc: 0.1820
Prev Val Results -- Loss: 0.2553 Acc: 0.3892
0.0003669836819171768
Val Results -- Loss: 0.2556 Acc: 0.4227


Epoch 3 Train -- Loss: 0.1081 Acc: 0.1874
Prev Val Results -- Loss: 0.2556 Acc: 0.4227
0.012323408812284442
Val Results -- Loss: 0.2680 Acc: 0.4225


Epoch 4 Train -- Loss: 0.1077 Acc: 0.2022
Prev Val Results -- Loss: 0.2680 Acc: 0.4225
0.00888926947116847
Val Results -- Loss: 0.2591 Acc: 0.4395


Epoch 5 Train -- Loss: 0.1075 Acc: 0.1980
Prev Val Results -- Loss: 0.2591 Acc: 0.4395
0.002442416131496483
Val Results -- Loss: 0.2566 Acc: 0.4317


Model:  3
Epoch 1 Train -- Loss: 0.1141 Acc: 0.1412
Val Results -- Loss: 0.2576 Acc: 0.3997


Epoch 2 Train -- Loss: 0.1084 Acc: 0.1762
Prev Val Results -- Loss: 0.2576 Acc: 0.3997
0.0043651729822158924
Val Results -- Loss: 0.2620 Acc: 0.4061


Epoch 3 Train -- Loss: 0.1081 Acc: 0.1895
Prev Val Results -- Loss: 0.2620 Acc: 0.4061
0.001573983341455476
Val Results -- Loss: 0.2604 Acc: 0.4164


Epoch 4 Train -- Loss: 0.1077 Acc: 0.1993
Prev Val Results -- Loss: 0.2604 Acc: 0.4164
0.003026567339897146
Val Results -- Loss: 0.2635 Acc: 0.4213


Epoch 5 Train -- Loss: 0.1073 Acc: 0.2067
Prev Val Results -- Loss: 0.2635 Acc: 0.4213
0.01016025924682612
Val Results -- Loss: 0.2533 Acc: 0.4343


Epoch 6 Train -- Loss: 0.1068 Acc: 0.2149
Prev Val Results -- Loss: 0.2533 Acc: 0.4343
0.0071910646259784605
Val Results -- Loss: 0.2605 Acc: 0.4376


Epoch 7 Train -- Loss: 0.1064 Acc: 0.2241
Prev Val Results -- Loss: 0.2605 Acc: 0.4376
0.004050151377916311
Val Results -- Loss: 0.2645 Acc: 0.4380


Model:  4
Epoch 1 Train -- Loss: 0.1099 Acc: 0.1505
Val Results -- Loss: 0.2639 Acc: 0.3952


Epoch 2 Train -- Loss: 0.1084 Acc: 0.1785
Prev Val Results -- Loss: 0.2639 Acc: 0.3952
0.002381136417388907
Val Results -- Loss: 0.2615 Acc: 0.3981


Epoch 3 Train -- Loss: 0.1081 Acc: 0.1826
Prev Val Results -- Loss: 0.2615 Acc: 0.3981
0.0032340079843998226
Val Results -- Loss: 0.2648 Acc: 0.4291


Epoch 4 Train -- Loss: 0.1077 Acc: 0.1908
Prev Val Results -- Loss: 0.2648 Acc: 0.4291
0.0005718974769115537
Val Results -- Loss: 0.2653 Acc: 0.4324


Epoch 5 Train -- Loss: 0.1073 Acc: 0.2026
Prev Val Results -- Loss: 0.2653 Acc: 0.4324
0.0034693138599395934
Val Results -- Loss: 0.2619 Acc: 0.4356


Model:  5
Epoch 1 Train -- Loss: 0.1096 Acc: 0.1501
Val Results -- Loss: 0.2652 Acc: 0.3997


Epoch 2 Train -- Loss: 0.1084 Acc: 0.1750
Prev Val Results -- Loss: 0.2652 Acc: 0.3997
0.006411247521638852
Val Results -- Loss: 0.2588 Acc: 0.3980


Epoch 3 Train -- Loss: 0.1081 Acc: 0.1808
Prev Val Results -- Loss: 0.2588 Acc: 0.3980
0.003385883688926672
Val Results -- Loss: 0.2622 Acc: 0.4059


Epoch 4 Train -- Loss: 0.1078 Acc: 0.1919
Prev Val Results -- Loss: 0.2622 Acc: 0.4059
0.0010203645229339697
Val Results -- Loss: 0.2612 Acc: 0.4163


Epoch 5 Train -- Loss: 0.1075 Acc: 0.2011
Prev Val Results -- Loss: 0.2612 Acc: 0.4163
0.0034302184879779762
Val Results -- Loss: 0.2578 Acc: 0.4485


Model:  6
Epoch 1 Train -- Loss: 0.1097 Acc: 0.1579
Val Results -- Loss: 0.2605 Acc: 0.3967


Epoch 2 Train -- Loss: 0.1081 Acc: 0.1832
Prev Val Results -- Loss: 0.2605 Acc: 0.3967
0.008648795038461665
Val Results -- Loss: 0.2692 Acc: 0.4237


Epoch 3 Train -- Loss: 0.1079 Acc: 0.1880
Prev Val Results -- Loss: 0.2692 Acc: 0.4237
0.0004910434782505191
Val Results -- Loss: 0.2697 Acc: 0.4121


Epoch 4 Train -- Loss: 0.1076 Acc: 0.1943
Prev Val Results -- Loss: 0.2697 Acc: 0.4121
0.0002468638718128302
Val Results -- Loss: 0.2699 Acc: 0.4343


Epoch 5 Train -- Loss: 0.1074 Acc: 0.1971
Prev Val Results -- Loss: 0.2699 Acc: 0.4343
0.015258714467287049
Val Results -- Loss: 0.2547 Acc: 0.4367


Epoch 6 Train -- Loss: 0.1067 Acc: 0.2134
Prev Val Results -- Loss: 0.2547 Acc: 0.4367
0.0010345579981803632
Val Results -- Loss: 0.2557 Acc: 0.4329


Model:  7
Epoch 1 Train -- Loss: 0.1107 Acc: 0.1550
Val Results -- Loss: 0.2634 Acc: 0.3917


Epoch 2 Train -- Loss: 0.1084 Acc: 0.1752
Prev Val Results -- Loss: 0.2634 Acc: 0.3917
0.0019518838226795232
Val Results -- Loss: 0.2614 Acc: 0.4143


Epoch 3 Train -- Loss: 0.1081 Acc: 0.1867
Prev Val Results -- Loss: 0.2614 Acc: 0.4143
0.006237203985452633
Val Results -- Loss: 0.2677 Acc: 0.3984


Epoch 4 Train -- Loss: 0.1078 Acc: 0.1940
Prev Val Results -- Loss: 0.2677 Acc: 0.3984
0.015387630850076661
Val Results -- Loss: 0.2523 Acc: 0.4240


Epoch 5 Train -- Loss: 0.1076 Acc: 0.2007
Prev Val Results -- Loss: 0.2523 Acc: 0.4240
0.0049412324726581525
Val Results -- Loss: 0.2572 Acc: 0.4185


Model:  8
Epoch 1 Train -- Loss: 0.1104 Acc: 0.1472
Val Results -- Loss: 0.2612 Acc: 0.3839


Epoch 2 Train -- Loss: 0.1084 Acc: 0.1777
Prev Val Results -- Loss: 0.2612 Acc: 0.3839
0.005659235477447511
Val Results -- Loss: 0.2668 Acc: 0.4036


Epoch 3 Train -- Loss: 0.1080 Acc: 0.1809
Prev Val Results -- Loss: 0.2668 Acc: 0.4036
0.0009976296424865638
Val Results -- Loss: 0.2678 Acc: 0.4200


Epoch 4 Train -- Loss: 0.1078 Acc: 0.1946
Prev Val Results -- Loss: 0.2678 Acc: 0.4200
0.0021792980730533373
Val Results -- Loss: 0.2700 Acc: 0.4244


Epoch 5 Train -- Loss: 0.1075 Acc: 0.1977
Prev Val Results -- Loss: 0.2700 Acc: 0.4244
0.010538441956043254
Val Results -- Loss: 0.2595 Acc: 0.4249


Epoch 6 Train -- Loss: 0.1068 Acc: 0.2140
Prev Val Results -- Loss: 0.2595 Acc: 0.4249
0.004939555287361175
Val Results -- Loss: 0.2644 Acc: 0.4508


Model:  9
Epoch 1 Train -- Loss: 0.1103 Acc: 0.1518
Val Results -- Loss: 0.2616 Acc: 0.3935


Epoch 2 Train -- Loss: 0.1083 Acc: 0.1761
Prev Val Results -- Loss: 0.2616 Acc: 0.3935
0.0008460883796215235
Val Results -- Loss: 0.2625 Acc: 0.4099


Epoch 3 Train -- Loss: 0.1081 Acc: 0.1864
Prev Val Results -- Loss: 0.2625 Acc: 0.4099
0.007936821073293687
Val Results -- Loss: 0.2545 Acc: 0.4176


Epoch 4 Train -- Loss: 0.1079 Acc: 0.1929
Prev Val Results -- Loss: 0.2545 Acc: 0.4176
0.01658921122550966
Val Results -- Loss: 0.2711 Acc: 0.4247


Epoch 5 Train -- Loss: 0.1075 Acc: 0.2018
Prev Val Results -- Loss: 0.2711 Acc: 0.4247
0.006718985021114343
Val Results -- Loss: 0.2778 Acc: 0.4243


Epoch 6 Train -- Loss: 0.1068 Acc: 0.2156
Prev Val Results -- Loss: 0.2778 Acc: 0.4243
0.01538237088918687
Val Results -- Loss: 0.2625 Acc: 0.4433


Epoch 7 Train -- Loss: 0.1063 Acc: 0.2238
Prev Val Results -- Loss: 0.2625 Acc: 0.4433
0.0012075619995594034
Val Results -- Loss: 0.2613 Acc: 0.4525


Model:  10
Epoch 1 Train -- Loss: 0.1100 Acc: 0.1587
Val Results -- Loss: 0.2615 Acc: 0.4165


Epoch 2 Train -- Loss: 0.1082 Acc: 0.1796
Prev Val Results -- Loss: 0.2615 Acc: 0.4165
0.0049380476176738575
Val Results -- Loss: 0.2664 Acc: 0.4120


Epoch 3 Train -- Loss: 0.1078 Acc: 0.1894
Prev Val Results -- Loss: 0.2664 Acc: 0.4120
0.010164543926715841
Val Results -- Loss: 0.2563 Acc: 0.4307


Epoch 4 Train -- Loss: 0.1077 Acc: 0.1966
Prev Val Results -- Loss: 0.2563 Acc: 0.4307
0.007559237778186789
Val Results -- Loss: 0.2638 Acc: 0.4273


Epoch 5 Train -- Loss: 0.1073 Acc: 0.2048
Prev Val Results -- Loss: 0.2638 Acc: 0.4273
0.0037294537425041074
Val Results -- Loss: 0.2601 Acc: 0.4301


<class 'numpy.ndarray'>
Best Model:  1
Test results -- Loss: 0.2649 Acc: 0.3333
precision: [0.41282746 0.34095634 0.433942  ]
recall: [0.457 0.328 0.404]
fscore: [0.43379212 0.3343527  0.41843604]
support: [1000 1000 1000]
Pleural Other :  0.60658025
Pneumonia :  0.509852
Support Devices :  0.61771575


Best Model:  2
Test results -- Loss: 0.2601 Acc: 0.3333
precision: [0.38501292 0.33757339 0.4247246 ]
recall: [0.447 0.345 0.347]
fscore: [0.41369736 0.34124629 0.38194827]
support: [1000 1000 1000]
Pleural Other :  0.59518225
Pneumonia :  0.5202145
Support Devices :  0.61324475


Best Model:  3
Test results -- Loss: 0.2730 Acc: 0.3333
precision: [0.41366574 0.36761488 0.43070788]
recall: [0.448 0.336 0.432]
fscore: [0.43014882 0.35109718 0.43135297]
support: [1000 1000 1000]
Pleural Other :  0.5899407499999999
Pneumonia :  0.5276825
Support Devices :  0.59950225


Best Model:  4
Test results -- Loss: 0.2660 Acc: 0.3333
precision: [0.39417989 0.34801289 0.40641711]
recall: [0.447 0.324 0.38 ]
fscore: [0.41893158 0.33557742 0.39276486]
support: [1000 1000 1000]
Pleural Other :  0.58418475
Pneumonia :  0.51633
Support Devices :  0.59022675


Best Model:  5
Test results -- Loss: 0.2606 Acc: 0.3333
precision: [0.42394504 0.32283465 0.45421245]
recall: [0.432 0.287 0.496]
fscore: [0.42793462 0.30386448 0.47418738]
support: [1000 1000 1000]
Pleural Other :  0.61119025
Pneumonia :  0.49220975
Support Devices :  0.64951525


Best Model:  6
Test results -- Loss: 0.2611 Acc: 0.3333
precision: [0.37343358 0.3088685  0.39537713]
recall: [0.447 0.303 0.325]
fscore: [0.40691853 0.30590611 0.35675082]
support: [1000 1000 1000]
Pleural Other :  0.56535425
Pneumonia :  0.47091125
Support Devices :  0.5767985


Best Model:  7
Test results -- Loss: 0.2610 Acc: 0.3333
precision: [0.36741214 0.32407407 0.38273196]
recall: [0.46  0.315 0.297]
fscore: [0.40852575 0.31947262 0.33445946]
support: [1000 1000 1000]
Pleural Other :  0.55049875
Pneumonia :  0.48633249999999995
Support Devices :  0.561849


Best Model:  8
Test results -- Loss: 0.2685 Acc: 0.3333
precision: [0.3675527  0.30691057 0.40324324]
recall: [0.401 0.302 0.373]
fscore: [0.38354854 0.30443548 0.38753247]
support: [1000 1000 1000]
Pleural Other :  0.5699495
Pneumonia :  0.49026375
Support Devices :  0.59052125


Best Model:  9
Test results -- Loss: 0.2706 Acc: 0.3333
precision: [0.39963669 0.34653465 0.43939394]
recall: [0.44  0.315 0.435]
fscore: [0.41884817 0.33001572 0.43718593]
support: [1000 1000 1000]
Pleural Other :  0.5847159999999999
Pneumonia :  0.5024332499999999
Support Devices :  0.60657275


Best Model:  10
Test results -- Loss: 0.2661 Acc: 0.3333
precision: [0.41263441 0.32397661 0.38543897]
recall: [0.307 0.277 0.54 ]
fscore: [0.35206422 0.29865229 0.44981258]
support: [1000 1000 1000]
Pleural Other :  0.598901
Pneumonia :  0.48039825
Support Devices :  0.587324


[0.60658025 0.59518225 0.58994075 0.58418475 0.61119025 0.56535425
 0.55049875 0.5699495  0.584716   0.598901  ] [0.509852   0.5202145  0.5276825  0.51633    0.49220975 0.47091125
 0.4863325  0.49026375 0.50243325 0.48039825] [0.61771575 0.61324475 0.59950225 0.59022675 0.64951525 0.5767985
 0.561849   0.59052125 0.60657275 0.587324  ]
[[0.41282746 0.34095634 0.433942  ]
 [0.38501292 0.33757339 0.4247246 ]
 [0.41366574 0.36761488 0.43070788]
 [0.39417989 0.34801289 0.40641711]
 [0.42394504 0.32283465 0.45421245]
 [0.37343358 0.3088685  0.39537713]
 [0.36741214 0.32407407 0.38273196]
 [0.3675527  0.30691057 0.40324324]
 [0.39963669 0.34653465 0.43939394]
 [0.41263441 0.32397661 0.38543897]] 
 [[0.457 0.328 0.404]
 [0.447 0.345 0.347]
 [0.448 0.336 0.432]
 [0.447 0.324 0.38 ]
 [0.432 0.287 0.496]
 [0.447 0.303 0.325]
 [0.46  0.315 0.297]
 [0.401 0.302 0.373]
 [0.44  0.315 0.435]
 [0.307 0.277 0.54 ]] 
 [[0.43379212 0.3343527  0.41843604]
 [0.41369736 0.34124629 0.38194827]
 [0.43014882 0.35109718 0.43135297]
 [0.41893158 0.33557742 0.39276486]
 [0.42793462 0.30386448 0.47418738]
 [0.40691853 0.30590611 0.35675082]
 [0.40852575 0.31947262 0.33445946]
 [0.38354854 0.30443548 0.38753247]
 [0.41884817 0.33001572 0.43718593]
 [0.35206422 0.29865229 0.44981258]]
[0.395  0.3327 0.4156] 
 [0.4286 0.3132 0.4029] 
 [0.4094 0.3225 0.4064]
[0.0198 0.0179 0.0231] 
 [0.0434 0.0202 0.0715] 
 [0.0235 0.0175 0.0412]
[0.5856, 0.4997, 0.5993] 
 [0.0181, 0.0177, 0.0231]
Mean AUROC of  Pleural Other :  0.5856 
 Std AUROC of  Pleural Other : 0.0181
Mean AUROC of  Pneumonia :  0.4997 
 Std AUROC of  Pneumonia : 0.0177
Mean AUROC of  Support Devices :  0.5993 
 Std AUROC of  Support Devices : 0.0231
[0.1106, 0.1083, 0.108, 0.1077, 0.1075, 0.1071, 0.1068, 0.1098, 0.1083, 0.1081, 0.1077, 0.1075, 0.1141, 0.1084, 0.1081, 0.1077, 0.1073, 0.1068, 0.1064, 0.1099, 0.1084, 0.1081, 0.1077, 0.1073, 0.1096, 0.1084, 0.1081, 0.1078, 0.1075, 0.1097, 0.1081, 0.1079, 0.1076, 0.1074, 0.1067, 0.1107, 0.1084, 0.1081, 0.1078, 0.1076, 0.1104, 0.1084, 0.108, 0.1078, 0.1075, 0.1068, 0.1103, 0.1083, 0.1081, 0.1079, 0.1075, 0.1068, 0.1063, 0.11, 0.1082, 0.1078, 0.1077, 0.1073] [0.1555, 0.1809, 0.1906, 0.1977, 0.2047, 0.2085, 0.2163, 0.1575, 0.182, 0.1874, 0.2022, 0.198, 0.1412, 0.1762, 0.1895, 0.1993, 0.2067, 0.2149, 0.2241, 0.1505, 0.1785, 0.1826, 0.1908, 0.2026, 0.1501, 0.175, 0.1808, 0.1919, 0.2011, 0.1579, 0.1832, 0.188, 0.1943, 0.1971, 0.2134, 0.155, 0.1752, 0.1867, 0.194, 0.2007, 0.1472, 0.1777, 0.1809, 0.1946, 0.1977, 0.214, 0.1518, 0.1761, 0.1864, 0.1929, 0.2018, 0.2156, 0.2238, 0.1587, 0.1796, 0.1894, 0.1966, 0.2048]
[0.2696, 0.257, 0.2571, 0.2637, 0.2506, 0.2564, 0.2619, 0.2553, 0.2556, 0.268, 0.2591, 0.2566, 0.2576, 0.262, 0.2604, 0.2635, 0.2533, 0.2605, 0.2645, 0.2639, 0.2615, 0.2648, 0.2653, 0.2619, 0.2652, 0.2588, 0.2622, 0.2612, 0.2578, 0.2605, 0.2692, 0.2697, 0.2699, 0.2547, 0.2557, 0.2634, 0.2614, 0.2677, 0.2523, 0.2572, 0.2612, 0.2668, 0.2678, 0.27, 0.2595, 0.2644, 0.2616, 0.2625, 0.2545, 0.2711, 0.2778, 0.2625, 0.2613, 0.2615, 0.2664, 0.2563, 0.2638, 0.2601] [0.3907, 0.3956, 0.4224, 0.4095, 0.4368, 0.446, 0.4265, 0.3892, 0.4227, 0.4225, 0.4395, 0.4317, 0.3997, 0.4061, 0.4164, 0.4213, 0.4343, 0.4376, 0.438, 0.3952, 0.3981, 0.4291, 0.4324, 0.4356, 0.3997, 0.398, 0.4059, 0.4163, 0.4485, 0.3967, 0.4237, 0.4121, 0.4343, 0.4367, 0.4329, 0.3917, 0.4143, 0.3984, 0.424, 0.4185, 0.3839, 0.4036, 0.42, 0.4244, 0.4249, 0.4508, 0.3935, 0.4099, 0.4176, 0.4247, 0.4243, 0.4433, 0.4525, 0.4165, 0.412, 0.4307, 0.4273, 0.4301]
