Time to load train arrays
(array(['Consolidation', 'Effusion', 'Fibrosis', 'Infiltration', 'Mass',
       'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumothorax'],
      dtype='<U18'), array([ 1310,  3955,   727,  9547,  2139, 10000,  2705,  1126,  2194]))
Time to load train arrays
(array(['Cardiomegaly', 'Edema', 'Emphysema'], dtype='<U12'), array([1093,  628,  892]))
Time to load train arrays
(array(['Atelectasis', 'Hernia', 'Pneumonia'], dtype='<U11'), array([4215,  110,  322]))
Model:  1
Epoch 1 Train -- Loss: 0.0991 Acc: 0.1366
Val Results -- Loss: 0.2619 Acc: 0.4731


Epoch 2 Train -- Loss: 0.0980 Acc: 0.1528
Prev Val Results -- Loss: 0.2619 Acc: 0.4731
0.010849298536777519
Val Results -- Loss: 0.2510 Acc: 0.4825


Epoch 3 Train -- Loss: 0.0978 Acc: 0.1592
Prev Val Results -- Loss: 0.2510 Acc: 0.4825
0.013460859000682834
Val Results -- Loss: 0.2645 Acc: 0.4959


Epoch 4 Train -- Loss: 0.0977 Acc: 0.1622
Prev Val Results -- Loss: 0.2645 Acc: 0.4959
0.007247121810913082
Val Results -- Loss: 0.2573 Acc: 0.4911


Epoch 5 Train -- Loss: 0.0976 Acc: 0.1660
Prev Val Results -- Loss: 0.2573 Acc: 0.4911
0.0034583592414855757
Val Results -- Loss: 0.2607 Acc: 0.5023


Model:  2
Epoch 1 Train -- Loss: 0.0991 Acc: 0.1353
Val Results -- Loss: 0.2628 Acc: 0.4731


Epoch 2 Train -- Loss: 0.0980 Acc: 0.1540
Prev Val Results -- Loss: 0.2628 Acc: 0.4731
0.0008358642756938761
Val Results -- Loss: 0.2619 Acc: 0.4871


Epoch 3 Train -- Loss: 0.0978 Acc: 0.1586
Prev Val Results -- Loss: 0.2619 Acc: 0.4871
0.0022277643680572168
Val Results -- Loss: 0.2642 Acc: 0.4888


Epoch 4 Train -- Loss: 0.0977 Acc: 0.1615
Prev Val Results -- Loss: 0.2642 Acc: 0.4888
6.469857692720238e-05
Val Results -- Loss: 0.2641 Acc: 0.4961


Epoch 5 Train -- Loss: 0.0978 Acc: 0.1625
Prev Val Results -- Loss: 0.2641 Acc: 0.4961
0.0014787941277026873
Val Results -- Loss: 0.2626 Acc: 0.4996


Model:  3
Epoch 1 Train -- Loss: 0.1004 Acc: 0.1314
Val Results -- Loss: 0.2701 Acc: 0.4716


Epoch 2 Train -- Loss: 0.0981 Acc: 0.1519
Prev Val Results -- Loss: 0.2701 Acc: 0.4716
0.008924948066473037
Val Results -- Loss: 0.2612 Acc: 0.4899


Epoch 3 Train -- Loss: 0.0978 Acc: 0.1588
Prev Val Results -- Loss: 0.2612 Acc: 0.4899
0.003009221673011764
Val Results -- Loss: 0.2582 Acc: 0.4915


Epoch 4 Train -- Loss: 0.0978 Acc: 0.1565
Prev Val Results -- Loss: 0.2582 Acc: 0.4915
0.007146192193031309
Val Results -- Loss: 0.2511 Acc: 0.5020


Epoch 5 Train -- Loss: 0.0977 Acc: 0.1604
Prev Val Results -- Loss: 0.2511 Acc: 0.5020
0.01225942909717559
Val Results -- Loss: 0.2633 Acc: 0.4864


Epoch 6 Train -- Loss: 0.0975 Acc: 0.1687
Prev Val Results -- Loss: 0.2633 Acc: 0.4864
0.00023998421430587724
Val Results -- Loss: 0.2631 Acc: 0.4880


Model:  4
Epoch 1 Train -- Loss: 0.1005 Acc: 0.1256
Val Results -- Loss: 0.2737 Acc: 0.4647


Epoch 2 Train -- Loss: 0.0983 Acc: 0.1503
Prev Val Results -- Loss: 0.2737 Acc: 0.4647
0.017610929965972855
Val Results -- Loss: 0.2561 Acc: 0.4803


Epoch 3 Train -- Loss: 0.0980 Acc: 0.1608
Prev Val Results -- Loss: 0.2561 Acc: 0.4803
0.002807760655879954
Val Results -- Loss: 0.2589 Acc: 0.5001


Epoch 4 Train -- Loss: 0.0979 Acc: 0.1621
Prev Val Results -- Loss: 0.2589 Acc: 0.5001
0.005702547878026931
Val Results -- Loss: 0.2646 Acc: 0.4947


Epoch 5 Train -- Loss: 0.0977 Acc: 0.1620
Prev Val Results -- Loss: 0.2646 Acc: 0.4947
0.003780411899089786
Val Results -- Loss: 0.2608 Acc: 0.4893


Model:  5
Epoch 1 Train -- Loss: 0.0993 Acc: 0.1360
Val Results -- Loss: 0.2663 Acc: 0.4781


Epoch 2 Train -- Loss: 0.0981 Acc: 0.1509
Prev Val Results -- Loss: 0.2663 Acc: 0.4781
0.00998411393165588
Val Results -- Loss: 0.2563 Acc: 0.5037


Epoch 3 Train -- Loss: 0.0979 Acc: 0.1606
Prev Val Results -- Loss: 0.2563 Acc: 0.5037
0.011888290762901266
Val Results -- Loss: 0.2682 Acc: 0.4923


Epoch 4 Train -- Loss: 0.0979 Acc: 0.1603
Prev Val Results -- Loss: 0.2682 Acc: 0.4923
0.010481559038162225
Val Results -- Loss: 0.2577 Acc: 0.4971


Epoch 5 Train -- Loss: 0.0978 Acc: 0.1620
Prev Val Results -- Loss: 0.2577 Acc: 0.4971
0.010436615586280812
Val Results -- Loss: 0.2473 Acc: 0.4867


Epoch 6 Train -- Loss: 0.0974 Acc: 0.1706
Prev Val Results -- Loss: 0.2473 Acc: 0.4867
0.011087459892034551
Val Results -- Loss: 0.2584 Acc: 0.5091


Epoch 7 Train -- Loss: 0.0976 Acc: 0.1659
Prev Val Results -- Loss: 0.2584 Acc: 0.5091
0.0016658390164375758
Val Results -- Loss: 0.2567 Acc: 0.5040


Model:  6
Epoch 1 Train -- Loss: 0.0992 Acc: 0.1352
Val Results -- Loss: 0.2636 Acc: 0.4648


Epoch 2 Train -- Loss: 0.0981 Acc: 0.1532
Prev Val Results -- Loss: 0.2636 Acc: 0.4648
0.0034580552577972434
Val Results -- Loss: 0.2601 Acc: 0.4949


Epoch 3 Train -- Loss: 0.0978 Acc: 0.1622
Prev Val Results -- Loss: 0.2601 Acc: 0.4949
0.00021240362524987955
Val Results -- Loss: 0.2603 Acc: 0.4980


Epoch 4 Train -- Loss: 0.0978 Acc: 0.1593
Prev Val Results -- Loss: 0.2603 Acc: 0.4980
0.002757724523544336
Val Results -- Loss: 0.2576 Acc: 0.5025


Epoch 5 Train -- Loss: 0.0977 Acc: 0.1593
Prev Val Results -- Loss: 0.2576 Acc: 0.5025
0.0022575475871562944
Val Results -- Loss: 0.2598 Acc: 0.5127


Model:  7
Epoch 1 Train -- Loss: 0.1001 Acc: 0.1346
Val Results -- Loss: 0.2680 Acc: 0.4636


Epoch 2 Train -- Loss: 0.0981 Acc: 0.1483
Prev Val Results -- Loss: 0.2680 Acc: 0.4636
0.010525796443223934
Val Results -- Loss: 0.2574 Acc: 0.4885


Epoch 3 Train -- Loss: 0.0979 Acc: 0.1601
Prev Val Results -- Loss: 0.2574 Acc: 0.4885
0.001468990206718479
Val Results -- Loss: 0.2560 Acc: 0.4785


Epoch 4 Train -- Loss: 0.0978 Acc: 0.1589
Prev Val Results -- Loss: 0.2560 Acc: 0.4785
0.006287725627422358
Val Results -- Loss: 0.2623 Acc: 0.4879


Epoch 5 Train -- Loss: 0.0978 Acc: 0.1642
Prev Val Results -- Loss: 0.2623 Acc: 0.4879
0.003628923982381793
Val Results -- Loss: 0.2586 Acc: 0.4948


Model:  8
Epoch 1 Train -- Loss: 0.0996 Acc: 0.1346
Val Results -- Loss: 0.2631 Acc: 0.4811


Epoch 2 Train -- Loss: 0.0980 Acc: 0.1557
Prev Val Results -- Loss: 0.2631 Acc: 0.4811
0.004784608393907597
Val Results -- Loss: 0.2583 Acc: 0.4880


Epoch 3 Train -- Loss: 0.0979 Acc: 0.1611
Prev Val Results -- Loss: 0.2583 Acc: 0.4880
0.012727336108684595
Val Results -- Loss: 0.2710 Acc: 0.4951


Epoch 4 Train -- Loss: 0.0978 Acc: 0.1623
Prev Val Results -- Loss: 0.2710 Acc: 0.4951
0.011318609833717352
Val Results -- Loss: 0.2597 Acc: 0.5043


Epoch 5 Train -- Loss: 0.0977 Acc: 0.1636
Prev Val Results -- Loss: 0.2597 Acc: 0.5043
0.004930499643087338
Val Results -- Loss: 0.2646 Acc: 0.4932


Model:  9
Epoch 1 Train -- Loss: 0.1000 Acc: 0.1362
Val Results -- Loss: 0.2652 Acc: 0.4808


Epoch 2 Train -- Loss: 0.0981 Acc: 0.1536
Prev Val Results -- Loss: 0.2652 Acc: 0.4808
0.0012443859279155922
Val Results -- Loss: 0.2664 Acc: 0.4752


Epoch 3 Train -- Loss: 0.0980 Acc: 0.1575
Prev Val Results -- Loss: 0.2664 Acc: 0.4752
0.00244787248969075
Val Results -- Loss: 0.2640 Acc: 0.4920


Epoch 4 Train -- Loss: 0.0979 Acc: 0.1582
Prev Val Results -- Loss: 0.2640 Acc: 0.4920
0.0016931804120540184
Val Results -- Loss: 0.2656 Acc: 0.4880


Epoch 5 Train -- Loss: 0.0977 Acc: 0.1653
Prev Val Results -- Loss: 0.2656 Acc: 0.4880
0.005344719618558869
Val Results -- Loss: 0.2603 Acc: 0.4821


Model:  10
Epoch 1 Train -- Loss: 0.1000 Acc: 0.1328
Val Results -- Loss: 0.2623 Acc: 0.4821


Epoch 2 Train -- Loss: 0.0982 Acc: 0.1504
Prev Val Results -- Loss: 0.2623 Acc: 0.4821
0.0032768107652664247
Val Results -- Loss: 0.2656 Acc: 0.4791


Epoch 3 Train -- Loss: 0.0980 Acc: 0.1588
Prev Val Results -- Loss: 0.2656 Acc: 0.4791
0.00021478003263475376
Val Results -- Loss: 0.2654 Acc: 0.4848


Epoch 4 Train -- Loss: 0.0978 Acc: 0.1644
Prev Val Results -- Loss: 0.2654 Acc: 0.4848
0.0019957352876663337
Val Results -- Loss: 0.2674 Acc: 0.4960


Epoch 5 Train -- Loss: 0.0978 Acc: 0.1621
Prev Val Results -- Loss: 0.2674 Acc: 0.4960
0.013656843453645706
Val Results -- Loss: 0.2537 Acc: 0.5069


Epoch 6 Train -- Loss: 0.0976 Acc: 0.1680
Prev Val Results -- Loss: 0.2537 Acc: 0.5069
0.012220183789730055
Val Results -- Loss: 0.2659 Acc: 0.4995


Epoch 7 Train -- Loss: 0.0976 Acc: 0.1656
Prev Val Results -- Loss: 0.2659 Acc: 0.4995
0.004153459876775734
Val Results -- Loss: 0.2618 Acc: 0.5047


<class 'numpy.ndarray'>
Best Model:  1
Test results -- Loss: 0.2692 Acc: 0.3333
precision: [0.38810484 0.47009346 0.39552239]
recall: [0.385 0.503 0.371]
fscore: [0.38654618 0.48599034 0.38286894]
support: [1000 1000 1000]
Atelectasis :  0.56404
Hernia :  0.68147825
Pneumonia :  0.56099125


Best Model:  2
Test results -- Loss: 0.2732 Acc: 0.3333
precision: [0.4201995  0.49027237 0.39101862]
recall: [0.337 0.63  0.357]
fscore: [0.37402886 0.55142232 0.37323576]
support: [1000 1000 1000]
Atelectasis :  0.571774
Hernia :  0.7276325
Pneumonia :  0.556929


Best Model:  3
Test results -- Loss: 0.2718 Acc: 0.3333
precision: [0.3654661  0.46314908 0.37819026]
recall: [0.345 0.553 0.326]
fscore: [0.35493827 0.5041021  0.35016112]
support: [1000 1000 1000]
Atelectasis :  0.53443775
Hernia :  0.68057225
Pneumonia :  0.561804


Best Model:  4
Test results -- Loss: 0.2700 Acc: 0.3333
precision: [0.41204437 0.438072   0.39452055]
recall: [0.26  0.718 0.288]
fscore: [0.31882281 0.54414551 0.33294798]
support: [1000 1000 1000]
Atelectasis :  0.54650225
Hernia :  0.700368
Pneumonia :  0.5577175


Best Model:  5
Test results -- Loss: 0.2664 Acc: 0.3333
precision: [0.39626352 0.48847926 0.3752784 ]
recall: [0.403 0.53  0.337]
fscore: [0.39960337 0.50839329 0.35511064]
support: [1000 1000 1000]
Atelectasis :  0.564227
Hernia :  0.7090277500000001
Pneumonia :  0.53586125


Best Model:  6
Test results -- Loss: 0.2693 Acc: 0.3333
precision: [0.39029768 0.46324181 0.39937759]
recall: [0.354 0.523 0.385]
fscore: [0.37126377 0.49131047 0.39205703]
support: [1000 1000 1000]
Atelectasis :  0.56505225
Hernia :  0.68172
Pneumonia :  0.56056825


Best Model:  7
Test results -- Loss: 0.2662 Acc: 0.3333
precision: [0.38618246 0.46085233 0.39791183]
recall: [0.436 0.465 0.343]
fscore: [0.40958196 0.46291687 0.36842105]
support: [1000 1000 1000]
Atelectasis :  0.5673545
Hernia :  0.6809029999999999
Pneumonia :  0.5662674999999999


Best Model:  8
Test results -- Loss: 0.2725 Acc: 0.3333
precision: [0.3785489  0.48169243 0.37804878]
recall: [0.36  0.592 0.31 ]
fscore: [0.36904152 0.5311799  0.34065934]
support: [1000 1000 1000]
Atelectasis :  0.557834
Hernia :  0.70434775
Pneumonia :  0.5528857500000001


Best Model:  9
Test results -- Loss: 0.2682 Acc: 0.3333
precision: [0.37556054 0.44537815 0.40958606]
recall: [0.335 0.53  0.376]
fscore: [0.35412262 0.48401826 0.39207508]
support: [1000 1000 1000]
Atelectasis :  0.5253715
Hernia :  0.6653227500000001
Pneumonia :  0.57706


Best Model:  10
Test results -- Loss: 0.2716 Acc: 0.3333
precision: [0.39568345 0.50298211 0.3956905 ]
recall: [0.385 0.506 0.404]
fscore: [0.39026863 0.50448654 0.39980208]
support: [1000 1000 1000]
Atelectasis :  0.56038325
Hernia :  0.71075625
Pneumonia :  0.5622765


[0.56404    0.571774   0.53443775 0.54650225 0.564227   0.56505225
 0.5673545  0.557834   0.5253715  0.56038325] [0.68147825 0.7276325  0.68057225 0.700368   0.70902775 0.68172
 0.680903   0.70434775 0.66532275 0.71075625] [0.56099125 0.556929   0.561804   0.5577175  0.53586125 0.56056825
 0.5662675  0.55288575 0.57706    0.5622765 ]
[[0.38810484 0.47009346 0.39552239]
 [0.4201995  0.49027237 0.39101862]
 [0.3654661  0.46314908 0.37819026]
 [0.41204437 0.438072   0.39452055]
 [0.39626352 0.48847926 0.3752784 ]
 [0.39029768 0.46324181 0.39937759]
 [0.38618246 0.46085233 0.39791183]
 [0.3785489  0.48169243 0.37804878]
 [0.37556054 0.44537815 0.40958606]
 [0.39568345 0.50298211 0.3956905 ]] 
 [[0.385 0.503 0.371]
 [0.337 0.63  0.357]
 [0.345 0.553 0.326]
 [0.26  0.718 0.288]
 [0.403 0.53  0.337]
 [0.354 0.523 0.385]
 [0.436 0.465 0.343]
 [0.36  0.592 0.31 ]
 [0.335 0.53  0.376]
 [0.385 0.506 0.404]] 
 [[0.38654618 0.48599034 0.38286894]
 [0.37402886 0.55142232 0.37323576]
 [0.35493827 0.5041021  0.35016112]
 [0.31882281 0.54414551 0.33294798]
 [0.39960337 0.50839329 0.35511064]
 [0.37126377 0.49131047 0.39205703]
 [0.40958196 0.46291687 0.36842105]
 [0.36904152 0.5311799  0.34065934]
 [0.35412262 0.48401826 0.39207508]
 [0.39026863 0.50448654 0.39980208]]
[0.3908 0.4704 0.3915] 
 [0.36   0.555  0.3497] 
 [0.3728 0.5068 0.3687]
[0.0156 0.0194 0.0105] 
 [0.045 0.07  0.034] 
 [0.0248 0.0267 0.0221]
[0.5557, 0.6942, 0.5592] 
 [0.0145, 0.0181, 0.0099]
Mean AUROC of  Atelectasis :  0.5557 
 Std AUROC of  Atelectasis : 0.0145
Mean AUROC of  Hernia :  0.6942 
 Std AUROC of  Hernia : 0.0181
Mean AUROC of  Pneumonia :  0.5592 
 Std AUROC of  Pneumonia : 0.0099
[0.0991, 0.098, 0.0978, 0.0977, 0.0976, 0.0991, 0.098, 0.0978, 0.0977, 0.0978, 0.1004, 0.0981, 0.0978, 0.0978, 0.0977, 0.0975, 0.1005, 0.0983, 0.098, 0.0979, 0.0977, 0.0993, 0.0981, 0.0979, 0.0979, 0.0978, 0.0974, 0.0976, 0.0992, 0.0981, 0.0978, 0.0978, 0.0977, 0.1001, 0.0981, 0.0979, 0.0978, 0.0978, 0.0996, 0.098, 0.0979, 0.0978, 0.0977, 0.1, 0.0981, 0.098, 0.0979, 0.0977, 0.1, 0.0982, 0.098, 0.0978, 0.0978, 0.0976, 0.0976] [0.1366, 0.1528, 0.1592, 0.1622, 0.166, 0.1353, 0.154, 0.1586, 0.1615, 0.1625, 0.1314, 0.1519, 0.1588, 0.1565, 0.1604, 0.1687, 0.1256, 0.1503, 0.1608, 0.1621, 0.162, 0.136, 0.1509, 0.1606, 0.1603, 0.162, 0.1706, 0.1659, 0.1352, 0.1532, 0.1622, 0.1593, 0.1593, 0.1346, 0.1483, 0.1601, 0.1589, 0.1642, 0.1346, 0.1557, 0.1611, 0.1623, 0.1636, 0.1362, 0.1536, 0.1575, 0.1582, 0.1653, 0.1328, 0.1504, 0.1588, 0.1644, 0.1621, 0.168, 0.1656]
[0.2619, 0.251, 0.2645, 0.2573, 0.2607, 0.2628, 0.2619, 0.2642, 0.2641, 0.2626, 0.2701, 0.2612, 0.2582, 0.2511, 0.2633, 0.2631, 0.2737, 0.2561, 0.2589, 0.2646, 0.2608, 0.2663, 0.2563, 0.2682, 0.2577, 0.2473, 0.2584, 0.2567, 0.2636, 0.2601, 0.2603, 0.2576, 0.2598, 0.268, 0.2574, 0.256, 0.2623, 0.2586, 0.2631, 0.2583, 0.271, 0.2597, 0.2646, 0.2652, 0.2664, 0.264, 0.2656, 0.2603, 0.2623, 0.2656, 0.2654, 0.2674, 0.2537, 0.2659, 0.2618] [0.4731, 0.4825, 0.4959, 0.4911, 0.5023, 0.4731, 0.4871, 0.4888, 0.4961, 0.4996, 0.4716, 0.4899, 0.4915, 0.502, 0.4864, 0.488, 0.4647, 0.4803, 0.5001, 0.4947, 0.4893, 0.4781, 0.5037, 0.4923, 0.4971, 0.4867, 0.5091, 0.504, 0.4648, 0.4949, 0.498, 0.5025, 0.5127, 0.4636, 0.4885, 0.4785, 0.4879, 0.4948, 0.4811, 0.488, 0.4951, 0.5043, 0.4932, 0.4808, 0.4752, 0.492, 0.488, 0.4821, 0.4821, 0.4791, 0.4848, 0.496, 0.5069, 0.4995, 0.5047]
