Time to load train arrays
(array(['Cardiomegaly', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis',
       'Infiltration', 'No Finding', 'Pleural_Thickening', 'Pneumothorax'],
      dtype='<U18'), array([ 1093,  1310,   628,   892,   727,  9547, 10000,  1126,  2194]))
Time to load train arrays
(array(['Atelectasis', 'Hernia', 'Pneumonia'], dtype='<U11'), array([4215,  110,  322]))
Time to load train arrays
(array(['Effusion', 'Mass', 'Nodule'], dtype='<U8'), array([3955, 2139, 2705]))
Model:  1
Epoch 1 Train -- Loss: 0.0993 Acc: 0.1595
Val Results -- Loss: 0.2688 Acc: 0.4163


Epoch 2 Train -- Loss: 0.0967 Acc: 0.1830
Prev Val Results -- Loss: 0.2688 Acc: 0.4163
0.0026562426686286833
Val Results -- Loss: 0.2715 Acc: 0.4265


Epoch 3 Train -- Loss: 0.0961 Acc: 0.1974
Prev Val Results -- Loss: 0.2715 Acc: 0.4265
0.0010202325284481284
Val Results -- Loss: 0.2725 Acc: 0.4189


Epoch 4 Train -- Loss: 0.0959 Acc: 0.2012
Prev Val Results -- Loss: 0.2725 Acc: 0.4189
0.00011673471331596907
Val Results -- Loss: 0.2724 Acc: 0.4231


Epoch 5 Train -- Loss: 0.0956 Acc: 0.2065
Prev Val Results -- Loss: 0.2724 Acc: 0.4231
0.009148203909397135
Val Results -- Loss: 0.2632 Acc: 0.4179


Epoch 6 Train -- Loss: 0.0949 Acc: 0.2180
Prev Val Results -- Loss: 0.2632 Acc: 0.4179
0.005755846887826932
Val Results -- Loss: 0.2690 Acc: 0.4261


Epoch 7 Train -- Loss: 0.0946 Acc: 0.2280
Prev Val Results -- Loss: 0.2690 Acc: 0.4261
0.00767973229289054
Val Results -- Loss: 0.2767 Acc: 0.4235


Epoch 8 Train -- Loss: 0.0945 Acc: 0.2307
Prev Val Results -- Loss: 0.2767 Acc: 0.4235
0.01128633621335029
Val Results -- Loss: 0.2654 Acc: 0.4237


Epoch 9 Train -- Loss: 0.0940 Acc: 0.2373
Prev Val Results -- Loss: 0.2654 Acc: 0.4237
0.0056748323142528645
Val Results -- Loss: 0.2711 Acc: 0.4151


Epoch 10 Train -- Loss: 0.0937 Acc: 0.2368
Prev Val Results -- Loss: 0.2711 Acc: 0.4151
0.0010846326053142175
Val Results -- Loss: 0.2721 Acc: 0.4348


Model:  2
Epoch 1 Train -- Loss: 0.0989 Acc: 0.1592
Val Results -- Loss: 0.2751 Acc: 0.4167


Epoch 2 Train -- Loss: 0.0968 Acc: 0.1828
Prev Val Results -- Loss: 0.2751 Acc: 0.4167
0.003593615651130644
Val Results -- Loss: 0.2715 Acc: 0.4239


Epoch 3 Train -- Loss: 0.0963 Acc: 0.1952
Prev Val Results -- Loss: 0.2715 Acc: 0.4239
0.006274909764528269
Val Results -- Loss: 0.2653 Acc: 0.4345


Epoch 4 Train -- Loss: 0.0959 Acc: 0.1992
Prev Val Results -- Loss: 0.2653 Acc: 0.4345
0.009419907718896836
Val Results -- Loss: 0.2747 Acc: 0.4313


Epoch 5 Train -- Loss: 0.0958 Acc: 0.2013
Prev Val Results -- Loss: 0.2747 Acc: 0.4313
0.01683610489964482
Val Results -- Loss: 0.2578 Acc: 0.4253


Epoch 6 Train -- Loss: 0.0952 Acc: 0.2107
Prev Val Results -- Loss: 0.2578 Acc: 0.4253
0.015457600235939006
Val Results -- Loss: 0.2733 Acc: 0.4275


Epoch 7 Train -- Loss: 0.0951 Acc: 0.2142
Prev Val Results -- Loss: 0.2733 Acc: 0.4275
0.00034592053294180136
Val Results -- Loss: 0.2736 Acc: 0.4288


Model:  3
Epoch 1 Train -- Loss: 0.0988 Acc: 0.1586
Val Results -- Loss: 0.2670 Acc: 0.4095


Epoch 2 Train -- Loss: 0.0968 Acc: 0.1808
Prev Val Results -- Loss: 0.2670 Acc: 0.4095
0.012790788441896461
Val Results -- Loss: 0.2798 Acc: 0.4203


Epoch 3 Train -- Loss: 0.0964 Acc: 0.1916
Prev Val Results -- Loss: 0.2798 Acc: 0.4203
0.01109867563843725
Val Results -- Loss: 0.2687 Acc: 0.4188


Epoch 4 Train -- Loss: 0.0961 Acc: 0.1965
Prev Val Results -- Loss: 0.2687 Acc: 0.4188
0.006569763332605338
Val Results -- Loss: 0.2753 Acc: 0.4272


Epoch 5 Train -- Loss: 0.0959 Acc: 0.2024
Prev Val Results -- Loss: 0.2753 Acc: 0.4272
0.0010478752255440038
Val Results -- Loss: 0.2742 Acc: 0.4169


Model:  4
Epoch 1 Train -- Loss: 0.1008 Acc: 0.1499
Val Results -- Loss: 0.2734 Acc: 0.4125


Epoch 2 Train -- Loss: 0.0966 Acc: 0.1868
Prev Val Results -- Loss: 0.2734 Acc: 0.4125
0.001953495144844053
Val Results -- Loss: 0.2714 Acc: 0.4280


Epoch 3 Train -- Loss: 0.0962 Acc: 0.1950
Prev Val Results -- Loss: 0.2714 Acc: 0.4280
0.006050699949264549
Val Results -- Loss: 0.2654 Acc: 0.4429


Epoch 4 Train -- Loss: 0.0959 Acc: 0.2022
Prev Val Results -- Loss: 0.2654 Acc: 0.4429
0.006457763910293568
Val Results -- Loss: 0.2718 Acc: 0.4157


Epoch 5 Train -- Loss: 0.0956 Acc: 0.2094
Prev Val Results -- Loss: 0.2718 Acc: 0.4157
0.0026544198989868484
Val Results -- Loss: 0.2745 Acc: 0.4107


Model:  5
Epoch 1 Train -- Loss: 0.1003 Acc: 0.1523
Val Results -- Loss: 0.2705 Acc: 0.4137


Epoch 2 Train -- Loss: 0.0968 Acc: 0.1844
Prev Val Results -- Loss: 0.2705 Acc: 0.4137
0.002820115685462976
Val Results -- Loss: 0.2676 Acc: 0.4113


Epoch 3 Train -- Loss: 0.0963 Acc: 0.1935
Prev Val Results -- Loss: 0.2676 Acc: 0.4113
0.002489818513393416
Val Results -- Loss: 0.2701 Acc: 0.4296


Epoch 4 Train -- Loss: 0.0959 Acc: 0.2009
Prev Val Results -- Loss: 0.2701 Acc: 0.4296
0.0008967571258544638
Val Results -- Loss: 0.2692 Acc: 0.4253


Epoch 5 Train -- Loss: 0.0956 Acc: 0.2118
Prev Val Results -- Loss: 0.2692 Acc: 0.4253
0.00857774603366851
Val Results -- Loss: 0.2778 Acc: 0.4191


Epoch 6 Train -- Loss: 0.0949 Acc: 0.2197
Prev Val Results -- Loss: 0.2778 Acc: 0.4191
0.0035886437296867024
Val Results -- Loss: 0.2814 Acc: 0.4172


Model:  6
Epoch 1 Train -- Loss: 0.0990 Acc: 0.1579
Val Results -- Loss: 0.2756 Acc: 0.4117


Epoch 2 Train -- Loss: 0.0969 Acc: 0.1851
Prev Val Results -- Loss: 0.2756 Acc: 0.4117
0.003195488989353179
Val Results -- Loss: 0.2724 Acc: 0.4307


Epoch 3 Train -- Loss: 0.0965 Acc: 0.1922
Prev Val Results -- Loss: 0.2724 Acc: 0.4307
0.006700852870941132
Val Results -- Loss: 0.2791 Acc: 0.4324


Epoch 4 Train -- Loss: 0.0959 Acc: 0.1974
Prev Val Results -- Loss: 0.2791 Acc: 0.4324
0.005382922947406776
Val Results -- Loss: 0.2738 Acc: 0.4224


Epoch 5 Train -- Loss: 0.0958 Acc: 0.2040
Prev Val Results -- Loss: 0.2738 Acc: 0.4224
0.007707527518272361
Val Results -- Loss: 0.2660 Acc: 0.4372


Epoch 6 Train -- Loss: 0.0951 Acc: 0.2126
Prev Val Results -- Loss: 0.2660 Acc: 0.4372
0.0006840132772922836
Val Results -- Loss: 0.2654 Acc: 0.4268


Model:  7
Epoch 1 Train -- Loss: 0.0990 Acc: 0.1542
Val Results -- Loss: 0.2731 Acc: 0.4212


Epoch 2 Train -- Loss: 0.0966 Acc: 0.1901
Prev Val Results -- Loss: 0.2731 Acc: 0.4212
0.004431676834821652
Val Results -- Loss: 0.2687 Acc: 0.4296


Epoch 3 Train -- Loss: 0.0962 Acc: 0.1999
Prev Val Results -- Loss: 0.2687 Acc: 0.4296
0.0023929142653942304
Val Results -- Loss: 0.2663 Acc: 0.4247


Epoch 4 Train -- Loss: 0.0958 Acc: 0.2029
Prev Val Results -- Loss: 0.2663 Acc: 0.4247
0.009252445936203002
Val Results -- Loss: 0.2755 Acc: 0.4289


Epoch 5 Train -- Loss: 0.0956 Acc: 0.2074
Prev Val Results -- Loss: 0.2755 Acc: 0.4289
0.003307545304298387
Val Results -- Loss: 0.2788 Acc: 0.4240


Model:  8
Epoch 1 Train -- Loss: 0.1112 Acc: 0.1101
Val Results -- Loss: 0.3333 Acc: 0.3333


Epoch 2 Train -- Loss: 0.1111 Acc: 0.1111
Prev Val Results -- Loss: 0.3333 Acc: 0.3333
0.0
Val Results -- Loss: 0.3333 Acc: 0.3333


Epoch 3 Train -- Loss: 0.1111 Acc: 0.1111
Prev Val Results -- Loss: 0.3333 Acc: 0.3333
0.0
Val Results -- Loss: 0.3333 Acc: 0.3333


Epoch 4 Train -- Loss: 0.1111 Acc: 0.1111
Prev Val Results -- Loss: 0.3333 Acc: 0.3333
0.0
Val Results -- Loss: 0.3333 Acc: 0.3333


Epoch 5 Train -- Loss: 0.1111 Acc: 0.1111
Prev Val Results -- Loss: 0.3333 Acc: 0.3333
0.0
Val Results -- Loss: 0.3333 Acc: 0.3333


Model:  9
Epoch 1 Train -- Loss: 0.0982 Acc: 0.1628
Val Results -- Loss: 0.2688 Acc: 0.4281


Epoch 2 Train -- Loss: 0.0965 Acc: 0.1906
Prev Val Results -- Loss: 0.2688 Acc: 0.4281
0.004765015512704862
Val Results -- Loss: 0.2735 Acc: 0.4329


Epoch 3 Train -- Loss: 0.0961 Acc: 0.1984
Prev Val Results -- Loss: 0.2735 Acc: 0.4329
0.00313448521494869
Val Results -- Loss: 0.2704 Acc: 0.4323


Epoch 4 Train -- Loss: 0.0958 Acc: 0.2040
Prev Val Results -- Loss: 0.2704 Acc: 0.4323
0.000678237855434416
Val Results -- Loss: 0.2711 Acc: 0.4304


Epoch 5 Train -- Loss: 0.0953 Acc: 0.2081
Prev Val Results -- Loss: 0.2711 Acc: 0.4304
0.00220440551638601
Val Results -- Loss: 0.2689 Acc: 0.4143


Model:  10
Epoch 1 Train -- Loss: 0.0983 Acc: 0.1606
Val Results -- Loss: 0.2739 Acc: 0.4231


Epoch 2 Train -- Loss: 0.0965 Acc: 0.1891
Prev Val Results -- Loss: 0.2739 Acc: 0.4231
0.0012649022340774918
Val Results -- Loss: 0.2726 Acc: 0.4280


Epoch 3 Train -- Loss: 0.0961 Acc: 0.2006
Prev Val Results -- Loss: 0.2726 Acc: 0.4280
0.004450520157814053
Val Results -- Loss: 0.2771 Acc: 0.4151


Epoch 4 Train -- Loss: 0.0954 Acc: 0.2128
Prev Val Results -- Loss: 0.2771 Acc: 0.4151
0.005096927583217614
Val Results -- Loss: 0.2720 Acc: 0.4257


Epoch 5 Train -- Loss: 0.0951 Acc: 0.2164
Prev Val Results -- Loss: 0.2720 Acc: 0.4257
0.003777154952287698
Val Results -- Loss: 0.2682 Acc: 0.4197


<class 'numpy.ndarray'>
Best Model:  1
Test results -- Loss: 0.2703 Acc: 0.3333
precision: [0.45948946 0.34445535 0.37037037]
recall: [0.414 0.351 0.4  ]
fscore: [0.43556023 0.34769688 0.38461538]
support: [1000 1000 1000]
Effusion :  0.63885
Mass :  0.53196625
Nodule :  0.5720704999999999


Best Model:  2
Test results -- Loss: 0.2763 Acc: 0.3333
precision: [0.39982654 0.34782609 0.36889898]
recall: [0.461 0.336 0.325]
fscore: [0.42823967 0.34181078 0.34556087]
support: [1000 1000 1000]
Effusion :  0.59894975
Mass :  0.53569775
Nodule :  0.55401325


Best Model:  3
Test results -- Loss: 0.2758 Acc: 0.3333
precision: [0.43296089 0.34250765 0.36931217]
recall: [0.465 0.336 0.349]
fscore: [0.44840887 0.33922261 0.35886889]
support: [1000 1000 1000]
Effusion :  0.6088975
Mass :  0.5057087499999999
Nodule :  0.54476325


Best Model:  4
Test results -- Loss: 0.2768 Acc: 0.3333
precision: [0.41805692 0.36332574 0.36446056]
recall: [0.426 0.319 0.402]
fscore: [0.42199108 0.33972311 0.38231098]
support: [1000 1000 1000]
Effusion :  0.60908575
Mass :  0.5477645
Nodule :  0.5575565


Best Model:  5
Test results -- Loss: 0.2812 Acc: 0.3333
precision: [0.44554455 0.36036961 0.40286482]
recall: [0.405 0.351 0.45 ]
fscore: [0.42430592 0.3556231  0.4251299 ]
support: [1000 1000 1000]
Effusion :  0.6261140000000001
Mass :  0.52043125
Nodule :  0.5926755


Best Model:  6
Test results -- Loss: 0.2669 Acc: 0.3333
precision: [0.4690367  0.36166008 0.38530466]
recall: [0.409 0.366 0.43 ]
fscore: [0.43696581 0.3638171  0.40642722]
support: [1000 1000 1000]
Effusion :  0.6207874999999999
Mass :  0.52607575
Nodule :  0.56709575


Best Model:  7
Test results -- Loss: 0.2809 Acc: 0.3333
precision: [0.40442478 0.3368984  0.38716578]
recall: [0.457 0.315 0.362]
fscore: [0.42910798 0.3255814  0.37416021]
support: [1000 1000 1000]
Effusion :  0.59026
Mass :  0.51678475
Nodule :  0.5614477499999999


Best Model:  8
Test results -- Loss: 0.3333 Acc: 0.3333
precision: [0.33333333 0.         0.        ]
recall: [1. 0. 0.]
fscore: [0.5 0.  0. ]
support: [1000 1000 1000]
Effusion :  0.5
Mass :  0.5
Nodule :  0.5


Best Model:  9
Test results -- Loss: 0.2723 Acc: 0.3333
precision: [0.42610365 0.33432245 0.36219641]
recall: [0.444 0.338 0.343]
fscore: [0.43486778 0.33615117 0.35233693]
support: [1000 1000 1000]
Effusion :  0.61680725
Mass :  0.502672
Nodule :  0.54574275


Best Model:  10
Test results -- Loss: 0.2708 Acc: 0.3333
precision: [0.4203629  0.33852544 0.37703349]
recall: [0.417 0.326 0.394]
fscore: [0.4186747  0.33214468 0.38533007]
support: [1000 1000 1000]
Effusion :  0.58741175
Mass :  0.51551725
Nodule :  0.5636147499999999


[0.63885    0.59894975 0.6088975  0.60908575 0.626114   0.6207875
 0.59026    0.5        0.61680725 0.58741175] [0.53196625 0.53569775 0.50570875 0.5477645  0.52043125 0.52607575
 0.51678475 0.5        0.502672   0.51551725] [0.5720705  0.55401325 0.54476325 0.5575565  0.5926755  0.56709575
 0.56144775 0.5        0.54574275 0.56361475]
[[0.45948946 0.34445535 0.37037037]
 [0.39982654 0.34782609 0.36889898]
 [0.43296089 0.34250765 0.36931217]
 [0.41805692 0.36332574 0.36446056]
 [0.44554455 0.36036961 0.40286482]
 [0.4690367  0.36166008 0.38530466]
 [0.40442478 0.3368984  0.38716578]
 [0.33333333 0.         0.        ]
 [0.42610365 0.33432245 0.36219641]
 [0.4203629  0.33852544 0.37703349]] 
 [[0.414 0.351 0.4  ]
 [0.461 0.336 0.325]
 [0.465 0.336 0.349]
 [0.426 0.319 0.402]
 [0.405 0.351 0.45 ]
 [0.409 0.366 0.43 ]
 [0.457 0.315 0.362]
 [1.    0.    0.   ]
 [0.444 0.338 0.343]
 [0.417 0.326 0.394]] 
 [[0.43556023 0.34769688 0.38461538]
 [0.42823967 0.34181078 0.34556087]
 [0.44840887 0.33922261 0.35886889]
 [0.42199108 0.33972311 0.38231098]
 [0.42430592 0.3556231  0.4251299 ]
 [0.43696581 0.3638171  0.40642722]
 [0.42910798 0.3255814  0.37416021]
 [0.5        0.         0.        ]
 [0.43486778 0.33615117 0.35233693]
 [0.4186747  0.33214468 0.38533007]]
[0.4209 0.313  0.3388] 
 [0.4898 0.3038 0.3455] 
 [0.4378 0.3082 0.3415]
[0.036  0.1048 0.1135] 
 [0.1714 0.1023 0.1211] 
 [0.0223 0.1033 0.1161]
[0.5997, 0.5203, 0.5559] 
 [0.0365, 0.0146, 0.0228]
Mean AUROC of  Effusion :  0.5997 
 Std AUROC of  Effusion : 0.0365
Mean AUROC of  Mass :  0.5203 
 Std AUROC of  Mass : 0.0146
Mean AUROC of  Nodule :  0.5559 
 Std AUROC of  Nodule : 0.0228
[0.0993, 0.0967, 0.0961, 0.0959, 0.0956, 0.0949, 0.0946, 0.0945, 0.094, 0.0937, 0.0989, 0.0968, 0.0963, 0.0959, 0.0958, 0.0952, 0.0951, 0.0988, 0.0968, 0.0964, 0.0961, 0.0959, 0.1008, 0.0966, 0.0962, 0.0959, 0.0956, 0.1003, 0.0968, 0.0963, 0.0959, 0.0956, 0.0949, 0.099, 0.0969, 0.0965, 0.0959, 0.0958, 0.0951, 0.099, 0.0966, 0.0962, 0.0958, 0.0956, 0.1112, 0.1111, 0.1111, 0.1111, 0.1111, 0.0982, 0.0965, 0.0961, 0.0958, 0.0953, 0.0983, 0.0965, 0.0961, 0.0954, 0.0951] [0.1595, 0.183, 0.1974, 0.2012, 0.2065, 0.218, 0.228, 0.2307, 0.2373, 0.2368, 0.1592, 0.1828, 0.1952, 0.1992, 0.2013, 0.2107, 0.2142, 0.1586, 0.1808, 0.1916, 0.1965, 0.2024, 0.1499, 0.1868, 0.195, 0.2022, 0.2094, 0.1523, 0.1844, 0.1935, 0.2009, 0.2118, 0.2197, 0.1579, 0.1851, 0.1922, 0.1974, 0.204, 0.2126, 0.1542, 0.1901, 0.1999, 0.2029, 0.2074, 0.1101, 0.1111, 0.1111, 0.1111, 0.1111, 0.1628, 0.1906, 0.1984, 0.204, 0.2081, 0.1606, 0.1891, 0.2006, 0.2128, 0.2164]
[0.2688, 0.2715, 0.2725, 0.2724, 0.2632, 0.269, 0.2767, 0.2654, 0.2711, 0.2721, 0.2751, 0.2715, 0.2653, 0.2747, 0.2578, 0.2733, 0.2736, 0.267, 0.2798, 0.2687, 0.2753, 0.2742, 0.2734, 0.2714, 0.2654, 0.2718, 0.2745, 0.2705, 0.2676, 0.2701, 0.2692, 0.2778, 0.2814, 0.2756, 0.2724, 0.2791, 0.2738, 0.266, 0.2654, 0.2731, 0.2687, 0.2663, 0.2755, 0.2788, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.2688, 0.2735, 0.2704, 0.2711, 0.2689, 0.2739, 0.2726, 0.2771, 0.272, 0.2682] [0.4163, 0.4265, 0.4189, 0.4231, 0.4179, 0.4261, 0.4235, 0.4237, 0.4151, 0.4348, 0.4167, 0.4239, 0.4345, 0.4313, 0.4253, 0.4275, 0.4288, 0.4095, 0.4203, 0.4188, 0.4272, 0.4169, 0.4125, 0.428, 0.4429, 0.4157, 0.4107, 0.4137, 0.4113, 0.4296, 0.4253, 0.4191, 0.4172, 0.4117, 0.4307, 0.4324, 0.4224, 0.4372, 0.4268, 0.4212, 0.4296, 0.4247, 0.4289, 0.424, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.4281, 0.4329, 0.4323, 0.4304, 0.4143, 0.4231, 0.428, 0.4151, 0.4257, 0.4197]
