Time to load train arrays
(array(['Consolidation', 'Fracture', 'Lung Lesion', 'Pleural Effusion',
       'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'],
      dtype='<U16'), array([1034, 1377,  782, 3572,  291,  423, 2274, 5303]))
Time to load train arrays
(array(['Atelectasis', 'Edema', 'Enlarged Cardiomediastinum'], dtype='<U26'), array([1716, 3080, 1028]))
Time to load train arrays
(array(['Cardiomegaly', 'Lung Opacity', 'No Finding'], dtype='<U12'), array([1539, 7000, 7000]))
Model:  1
Epoch 1 Train -- Loss: 0.1101 Acc: 0.1500
Val Results -- Loss: 0.2643 Acc: 0.3940


Epoch 2 Train -- Loss: 0.1087 Acc: 0.1650
Prev Val Results -- Loss: 0.2643 Acc: 0.3940
0.003633356392383602
Val Results -- Loss: 0.2607 Acc: 0.4192


Epoch 3 Train -- Loss: 0.1084 Acc: 0.1756
Prev Val Results -- Loss: 0.2607 Acc: 0.4192
0.010157925486564634
Val Results -- Loss: 0.2708 Acc: 0.4224


Epoch 4 Train -- Loss: 0.1079 Acc: 0.1906
Prev Val Results -- Loss: 0.2708 Acc: 0.4224
0.01140941497683523
Val Results -- Loss: 0.2594 Acc: 0.4213


Epoch 5 Train -- Loss: 0.1078 Acc: 0.1879
Prev Val Results -- Loss: 0.2594 Acc: 0.4213
0.004645880430936833
Val Results -- Loss: 0.2548 Acc: 0.4359


Model:  2
Epoch 1 Train -- Loss: 0.1103 Acc: 0.1404
Val Results -- Loss: 0.2644 Acc: 0.3807


Epoch 2 Train -- Loss: 0.1088 Acc: 0.1650
Prev Val Results -- Loss: 0.2644 Acc: 0.3807
0.0029057333469390545
Val Results -- Loss: 0.2673 Acc: 0.3940


Epoch 3 Train -- Loss: 0.1085 Acc: 0.1691
Prev Val Results -- Loss: 0.2673 Acc: 0.3940
0.0019262509942054584
Val Results -- Loss: 0.2654 Acc: 0.4268


Epoch 4 Train -- Loss: 0.1083 Acc: 0.1751
Prev Val Results -- Loss: 0.2654 Acc: 0.4268
0.005615308970212951
Val Results -- Loss: 0.2598 Acc: 0.4228


Epoch 5 Train -- Loss: 0.1079 Acc: 0.1867
Prev Val Results -- Loss: 0.2598 Acc: 0.4228
0.004074384331703151
Val Results -- Loss: 0.2557 Acc: 0.4268


Model:  3
Epoch 1 Train -- Loss: 0.1104 Acc: 0.1439
Val Results -- Loss: 0.2659 Acc: 0.3949


Epoch 2 Train -- Loss: 0.1088 Acc: 0.1634
Prev Val Results -- Loss: 0.2659 Acc: 0.3949
0.0005023482441902094
Val Results -- Loss: 0.2664 Acc: 0.4047


Epoch 3 Train -- Loss: 0.1086 Acc: 0.1645
Prev Val Results -- Loss: 0.2664 Acc: 0.4047
0.004293073832988714
Val Results -- Loss: 0.2621 Acc: 0.4021


Epoch 4 Train -- Loss: 0.1083 Acc: 0.1756
Prev Val Results -- Loss: 0.2621 Acc: 0.4021
2.873578667639265e-05
Val Results -- Loss: 0.2621 Acc: 0.4197


Epoch 5 Train -- Loss: 0.1081 Acc: 0.1861
Prev Val Results -- Loss: 0.2621 Acc: 0.4197
0.004365036934614153
Val Results -- Loss: 0.2665 Acc: 0.4273


Model:  4
Epoch 1 Train -- Loss: 0.1104 Acc: 0.1451
Val Results -- Loss: 0.2613 Acc: 0.3888


Epoch 2 Train -- Loss: 0.1087 Acc: 0.1657
Prev Val Results -- Loss: 0.2613 Acc: 0.3888
0.0014771775007247911
Val Results -- Loss: 0.2628 Acc: 0.4097


Epoch 3 Train -- Loss: 0.1084 Acc: 0.1771
Prev Val Results -- Loss: 0.2628 Acc: 0.4097
0.002419123262166978
Val Results -- Loss: 0.2604 Acc: 0.4241


Epoch 4 Train -- Loss: 0.1080 Acc: 0.1859
Prev Val Results -- Loss: 0.2604 Acc: 0.4241
0.004544080197811107
Val Results -- Loss: 0.2558 Acc: 0.4168


Epoch 5 Train -- Loss: 0.1078 Acc: 0.1923
Prev Val Results -- Loss: 0.2558 Acc: 0.4168
0.0014821265041828346
Val Results -- Loss: 0.2573 Acc: 0.4343


Model:  5
Epoch 1 Train -- Loss: 0.1107 Acc: 0.1506
Val Results -- Loss: 0.2696 Acc: 0.3912


Epoch 2 Train -- Loss: 0.1088 Acc: 0.1628
Prev Val Results -- Loss: 0.2696 Acc: 0.3912
0.013128016054630265
Val Results -- Loss: 0.2565 Acc: 0.3995


Epoch 3 Train -- Loss: 0.1084 Acc: 0.1762
Prev Val Results -- Loss: 0.2565 Acc: 0.3995
0.00970267644524575
Val Results -- Loss: 0.2662 Acc: 0.4252


Epoch 4 Train -- Loss: 0.1082 Acc: 0.1807
Prev Val Results -- Loss: 0.2662 Acc: 0.4252
0.018183042615652067
Val Results -- Loss: 0.2480 Acc: 0.4289


Epoch 5 Train -- Loss: 0.1079 Acc: 0.1875
Prev Val Results -- Loss: 0.2480 Acc: 0.4289
0.009941331893205618
Val Results -- Loss: 0.2580 Acc: 0.4349


Epoch 6 Train -- Loss: 0.1074 Acc: 0.2003
Prev Val Results -- Loss: 0.2580 Acc: 0.4349
0.001431740880012522
Val Results -- Loss: 0.2594 Acc: 0.4315


Model:  6
Epoch 1 Train -- Loss: 0.1102 Acc: 0.1443
Val Results -- Loss: 0.2597 Acc: 0.3959


Epoch 2 Train -- Loss: 0.1087 Acc: 0.1664
Prev Val Results -- Loss: 0.2597 Acc: 0.3959
0.0035783659219741915
Val Results -- Loss: 0.2633 Acc: 0.4243


Epoch 3 Train -- Loss: 0.1085 Acc: 0.1740
Prev Val Results -- Loss: 0.2633 Acc: 0.4243
0.0021812556385993886
Val Results -- Loss: 0.2611 Acc: 0.4164


Epoch 4 Train -- Loss: 0.1082 Acc: 0.1820
Prev Val Results -- Loss: 0.2611 Acc: 0.4164
0.001914288401603681
Val Results -- Loss: 0.2630 Acc: 0.4153


Epoch 5 Train -- Loss: 0.1079 Acc: 0.1939
Prev Val Results -- Loss: 0.2630 Acc: 0.4153
0.009069531261920949
Val Results -- Loss: 0.2540 Acc: 0.4193


Epoch 6 Train -- Loss: 0.1074 Acc: 0.2007
Prev Val Results -- Loss: 0.2540 Acc: 0.4193
0.008024988502264019
Val Results -- Loss: 0.2620 Acc: 0.4256


Epoch 7 Train -- Loss: 0.1072 Acc: 0.2055
Prev Val Results -- Loss: 0.2620 Acc: 0.4256
0.008798185706138606
Val Results -- Loss: 0.2532 Acc: 0.4301


Epoch 8 Train -- Loss: 0.1071 Acc: 0.2064
Prev Val Results -- Loss: 0.2532 Acc: 0.4301
0.011464230209589032
Val Results -- Loss: 0.2647 Acc: 0.4249


Epoch 9 Train -- Loss: 0.1068 Acc: 0.2139
Prev Val Results -- Loss: 0.2647 Acc: 0.4249
0.002674372881650955
Val Results -- Loss: 0.2620 Acc: 0.4247


Model:  7
Epoch 1 Train -- Loss: 0.1108 Acc: 0.1440
Val Results -- Loss: 0.2646 Acc: 0.3948


Epoch 2 Train -- Loss: 0.1087 Acc: 0.1633
Prev Val Results -- Loss: 0.2646 Acc: 0.3948
0.004803900688886642
Val Results -- Loss: 0.2598 Acc: 0.4116


Epoch 3 Train -- Loss: 0.1084 Acc: 0.1753
Prev Val Results -- Loss: 0.2598 Acc: 0.4116
0.002372912466526045
Val Results -- Loss: 0.2622 Acc: 0.4260


Epoch 4 Train -- Loss: 0.1080 Acc: 0.1874
Prev Val Results -- Loss: 0.2622 Acc: 0.4260
0.0019850961267948164
Val Results -- Loss: 0.2602 Acc: 0.4188


Epoch 5 Train -- Loss: 0.1077 Acc: 0.1925
Prev Val Results -- Loss: 0.2602 Acc: 0.4188
0.01293499881029131
Val Results -- Loss: 0.2731 Acc: 0.4123


Epoch 6 Train -- Loss: 0.1073 Acc: 0.2029
Prev Val Results -- Loss: 0.2731 Acc: 0.4123
0.008911832571029676
Val Results -- Loss: 0.2642 Acc: 0.4275


Epoch 7 Train -- Loss: 0.1070 Acc: 0.2096
Prev Val Results -- Loss: 0.2642 Acc: 0.4275
0.0039932833909988585
Val Results -- Loss: 0.2602 Acc: 0.4291


Model:  8
Epoch 1 Train -- Loss: 0.1121 Acc: 0.1416
Val Results -- Loss: 0.2624 Acc: 0.3829


Epoch 2 Train -- Loss: 0.1089 Acc: 0.1581
Prev Val Results -- Loss: 0.2624 Acc: 0.3829
0.001422790169715915
Val Results -- Loss: 0.2638 Acc: 0.4004


Epoch 3 Train -- Loss: 0.1086 Acc: 0.1710
Prev Val Results -- Loss: 0.2638 Acc: 0.4004
0.0026096205413341234
Val Results -- Loss: 0.2664 Acc: 0.4136


Epoch 4 Train -- Loss: 0.1082 Acc: 0.1789
Prev Val Results -- Loss: 0.2664 Acc: 0.4136
0.003920097887516016
Val Results -- Loss: 0.2625 Acc: 0.4207


Epoch 5 Train -- Loss: 0.1081 Acc: 0.1861
Prev Val Results -- Loss: 0.2625 Acc: 0.4207
0.002162866801023511
Val Results -- Loss: 0.2604 Acc: 0.4152


Model:  9
Epoch 1 Train -- Loss: 0.1101 Acc: 0.1464
Val Results -- Loss: 0.2750 Acc: 0.4023


Epoch 2 Train -- Loss: 0.1085 Acc: 0.1683
Prev Val Results -- Loss: 0.2750 Acc: 0.4023
0.0105954656302929
Val Results -- Loss: 0.2644 Acc: 0.4131


Epoch 3 Train -- Loss: 0.1081 Acc: 0.1770
Prev Val Results -- Loss: 0.2644 Acc: 0.4131
0.0030867539048194392
Val Results -- Loss: 0.2613 Acc: 0.4283


Epoch 4 Train -- Loss: 0.1078 Acc: 0.1880
Prev Val Results -- Loss: 0.2613 Acc: 0.4283
0.0004809592068195645
Val Results -- Loss: 0.2608 Acc: 0.4127


Epoch 5 Train -- Loss: 0.1076 Acc: 0.1958
Prev Val Results -- Loss: 0.2608 Acc: 0.4127
0.005203465700149512
Val Results -- Loss: 0.2556 Acc: 0.4311


Model:  10
Epoch 1 Train -- Loss: 0.1098 Acc: 0.1421
Val Results -- Loss: 0.2613 Acc: 0.3824


Epoch 2 Train -- Loss: 0.1088 Acc: 0.1612
Prev Val Results -- Loss: 0.2613 Acc: 0.3824
0.0012348439693450897
Val Results -- Loss: 0.2625 Acc: 0.3989


Epoch 3 Train -- Loss: 0.1085 Acc: 0.1755
Prev Val Results -- Loss: 0.2625 Acc: 0.3989
0.002623244374990452
Val Results -- Loss: 0.2599 Acc: 0.4091


Epoch 4 Train -- Loss: 0.1081 Acc: 0.1879
Prev Val Results -- Loss: 0.2599 Acc: 0.4091
0.0008269820511341286
Val Results -- Loss: 0.2590 Acc: 0.4211


Epoch 5 Train -- Loss: 0.1078 Acc: 0.1887
Prev Val Results -- Loss: 0.2590 Acc: 0.4211
0.0011863601207733332
Val Results -- Loss: 0.2602 Acc: 0.4389


<class 'numpy.ndarray'>
Best Model:  1
Test results -- Loss: 0.2569 Acc: 0.3333
precision: [0.42195368 0.38917263 0.5077821 ]
recall: [0.419 0.381 0.522]
fscore: [0.42047165 0.38504295 0.5147929 ]
support: [1000 1000 1000]
Cardiomegaly :  0.6081505
Lung Opacity :  0.557925
No Finding :  0.69926275


Best Model:  2
Test results -- Loss: 0.2570 Acc: 0.3333
precision: [0.4178499  0.39175258 0.52394636]
recall: [0.412 0.38  0.547]
fscore: [0.41490433 0.3857868  0.53522505]
support: [1000 1000 1000]
Cardiomegaly :  0.608013
Lung Opacity :  0.58243025
No Finding :  0.7326050000000001


Best Model:  3
Test results -- Loss: 0.2687 Acc: 0.3333
precision: [0.41722746 0.40809969 0.47836167]
recall: [0.31  0.393 0.619]
fscore: [0.35570855 0.40040754 0.5396687 ]
support: [1000 1000 1000]
Cardiomegaly :  0.5841652500000001
Lung Opacity :  0.5934792499999999
No Finding :  0.7129552499999999


Best Model:  4
Test results -- Loss: 0.2580 Acc: 0.3333
precision: [0.42545455 0.3984109  0.4984544 ]
recall: [0.351 0.351 0.645]
fscore: [0.38465753 0.37320574 0.56233653]
support: [1000 1000 1000]
Cardiomegaly :  0.59286825
Lung Opacity :  0.57055025
No Finding :  0.727192


Best Model:  5
Test results -- Loss: 0.2618 Acc: 0.3333
precision: [0.42116631 0.40837696 0.51921358]
recall: [0.39  0.39  0.581]
fscore: [0.40498442 0.39897698 0.54837187]
support: [1000 1000 1000]
Cardiomegaly :  0.6023345
Lung Opacity :  0.5831535000000001
No Finding :  0.72810575


Best Model:  6
Test results -- Loss: 0.2614 Acc: 0.3333
precision: [0.41294118 0.38409091 0.48661417]
recall: [0.351 0.338 0.618]
fscore: [0.37945946 0.35957447 0.54449339]
support: [1000 1000 1000]
Cardiomegaly :  0.5975825
Lung Opacity :  0.585762
No Finding :  0.7176984999999999


Best Model:  7
Test results -- Loss: 0.2617 Acc: 0.3333
precision: [0.43718593 0.41655886 0.45003494]
recall: [0.348 0.322 0.644]
fscore: [0.38752784 0.36322617 0.52982312]
support: [1000 1000 1000]
Cardiomegaly :  0.5843965
Lung Opacity :  0.5915855
No Finding :  0.6834060000000001


Best Model:  8
Test results -- Loss: 0.2619 Acc: 0.3333
precision: [0.4029484  0.39634146 0.44509517]
recall: [0.328 0.325 0.608]
fscore: [0.36163175 0.35714286 0.51394759]
support: [1000 1000 1000]
Cardiomegaly :  0.5748715
Lung Opacity :  0.5978285
No Finding :  0.6867272499999999


Best Model:  9
Test results -- Loss: 0.2602 Acc: 0.3333
precision: [0.4061569  0.41431452 0.53546454]
recall: [0.409 0.411 0.536]
fscore: [0.40757349 0.4126506  0.53573213]
support: [1000 1000 1000]
Cardiomegaly :  0.5762045
Lung Opacity :  0.58676675
No Finding :  0.710311


Best Model:  10
Test results -- Loss: 0.2616 Acc: 0.3333
precision: [0.42081949 0.39978094 0.50422297]
recall: [0.38  0.365 0.597]
fscore: [0.39936942 0.38159958 0.5467033 ]
support: [1000 1000 1000]
Cardiomegaly :  0.59436775
Lung Opacity :  0.59852375
No Finding :  0.7236475


[0.6081505  0.608013   0.58416525 0.59286825 0.6023345  0.5975825
 0.5843965  0.5748715  0.5762045  0.59436775] [0.557925   0.58243025 0.59347925 0.57055025 0.5831535  0.585762
 0.5915855  0.5978285  0.58676675 0.59852375] [0.69926275 0.732605   0.71295525 0.727192   0.72810575 0.7176985
 0.683406   0.68672725 0.710311   0.7236475 ]
[[0.42195368 0.38917263 0.5077821 ]
 [0.4178499  0.39175258 0.52394636]
 [0.41722746 0.40809969 0.47836167]
 [0.42545455 0.3984109  0.4984544 ]
 [0.42116631 0.40837696 0.51921358]
 [0.41294118 0.38409091 0.48661417]
 [0.43718593 0.41655886 0.45003494]
 [0.4029484  0.39634146 0.44509517]
 [0.4061569  0.41431452 0.53546454]
 [0.42081949 0.39978094 0.50422297]] 
 [[0.419 0.381 0.522]
 [0.412 0.38  0.547]
 [0.31  0.393 0.619]
 [0.351 0.351 0.645]
 [0.39  0.39  0.581]
 [0.351 0.338 0.618]
 [0.348 0.322 0.644]
 [0.328 0.325 0.608]
 [0.409 0.411 0.536]
 [0.38  0.365 0.597]] 
 [[0.42047165 0.38504295 0.5147929 ]
 [0.41490433 0.3857868  0.53522505]
 [0.35570855 0.40040754 0.5396687 ]
 [0.38465753 0.37320574 0.56233653]
 [0.40498442 0.39897698 0.54837187]
 [0.37945946 0.35957447 0.54449339]
 [0.38752784 0.36322617 0.52982312]
 [0.36163175 0.35714286 0.51394759]
 [0.40757349 0.4126506  0.53573213]
 [0.39936942 0.38159958 0.5467033 ]]
[0.4184 0.4007 0.4949] 
 [0.3698 0.3656 0.5917] 
 [0.3916 0.3818 0.5371]
[0.0092 0.0103 0.0286] 
 [0.0357 0.0289 0.0417] 
 [0.0207 0.0177 0.0142]
[0.5923, 0.5848, 0.7122] 
 [0.0115, 0.0119, 0.0164]
Mean AUROC of  Cardiomegaly :  0.5923 
 Std AUROC of  Cardiomegaly : 0.0115
Mean AUROC of  Lung Opacity :  0.5848 
 Std AUROC of  Lung Opacity : 0.0119
Mean AUROC of  No Finding :  0.7122 
 Std AUROC of  No Finding : 0.0164
[0.1101, 0.1087, 0.1084, 0.1079, 0.1078, 0.1103, 0.1088, 0.1085, 0.1083, 0.1079, 0.1104, 0.1088, 0.1086, 0.1083, 0.1081, 0.1104, 0.1087, 0.1084, 0.108, 0.1078, 0.1107, 0.1088, 0.1084, 0.1082, 0.1079, 0.1074, 0.1102, 0.1087, 0.1085, 0.1082, 0.1079, 0.1074, 0.1072, 0.1071, 0.1068, 0.1108, 0.1087, 0.1084, 0.108, 0.1077, 0.1073, 0.107, 0.1121, 0.1089, 0.1086, 0.1082, 0.1081, 0.1101, 0.1085, 0.1081, 0.1078, 0.1076, 0.1098, 0.1088, 0.1085, 0.1081, 0.1078] [0.15, 0.165, 0.1756, 0.1906, 0.1879, 0.1404, 0.165, 0.1691, 0.1751, 0.1867, 0.1439, 0.1634, 0.1645, 0.1756, 0.1861, 0.1451, 0.1657, 0.1771, 0.1859, 0.1923, 0.1506, 0.1628, 0.1762, 0.1807, 0.1875, 0.2003, 0.1443, 0.1664, 0.174, 0.182, 0.1939, 0.2007, 0.2055, 0.2064, 0.2139, 0.144, 0.1633, 0.1753, 0.1874, 0.1925, 0.2029, 0.2096, 0.1416, 0.1581, 0.171, 0.1789, 0.1861, 0.1464, 0.1683, 0.177, 0.188, 0.1958, 0.1421, 0.1612, 0.1755, 0.1879, 0.1887]
[0.2643, 0.2607, 0.2708, 0.2594, 0.2548, 0.2644, 0.2673, 0.2654, 0.2598, 0.2557, 0.2659, 0.2664, 0.2621, 0.2621, 0.2665, 0.2613, 0.2628, 0.2604, 0.2558, 0.2573, 0.2696, 0.2565, 0.2662, 0.248, 0.258, 0.2594, 0.2597, 0.2633, 0.2611, 0.263, 0.254, 0.262, 0.2532, 0.2647, 0.262, 0.2646, 0.2598, 0.2622, 0.2602, 0.2731, 0.2642, 0.2602, 0.2624, 0.2638, 0.2664, 0.2625, 0.2604, 0.275, 0.2644, 0.2613, 0.2608, 0.2556, 0.2613, 0.2625, 0.2599, 0.259, 0.2602] [0.394, 0.4192, 0.4224, 0.4213, 0.4359, 0.3807, 0.394, 0.4268, 0.4228, 0.4268, 0.3949, 0.4047, 0.4021, 0.4197, 0.4273, 0.3888, 0.4097, 0.4241, 0.4168, 0.4343, 0.3912, 0.3995, 0.4252, 0.4289, 0.4349, 0.4315, 0.3959, 0.4243, 0.4164, 0.4153, 0.4193, 0.4256, 0.4301, 0.4249, 0.4247, 0.3948, 0.4116, 0.426, 0.4188, 0.4123, 0.4275, 0.4291, 0.3829, 0.4004, 0.4136, 0.4207, 0.4152, 0.4023, 0.4131, 0.4283, 0.4127, 0.4311, 0.3824, 0.3989, 0.4091, 0.4211, 0.4389]
