Time to load train arrays
Time to load train arrays
Time to load train arrays
24732 (24732, 128, 128, 3)
24732
11584
11584
4647
4647
Model:  1
Epoch 1 Train -- Loss: 0.1927 Acc: 0.1328
Val Results -- Loss: 0.4478 Acc: 0.3288


Epoch 2 Train -- Loss: 0.4339 Acc: 0.3531
Prev Val Results -- Loss: 0.4478 Acc: 0.3288
0.0010116064996022467
Val Results -- Loss: 0.4488 Acc: 0.3336


Epoch 3 Train -- Loss: 0.4387 Acc: 0.3491
Prev Val Results -- Loss: 0.4488 Acc: 0.3336
0.001888363264032411
Val Results -- Loss: 0.4469 Acc: 0.3241


Epoch 4 Train -- Loss: 0.4244 Acc: 0.3645
Prev Val Results -- Loss: 0.4469 Acc: 0.3241
0.003911228683762147
Val Results -- Loss: 0.4430 Acc: 0.3337


Epoch 5 Train -- Loss: 0.4323 Acc: 0.3573
Prev Val Results -- Loss: 0.4430 Acc: 0.3337
0.001427540872915467
Val Results -- Loss: 0.4415 Acc: 0.3355


Model:  2
Epoch 1 Train -- Loss: 0.1916 Acc: 0.1353
Val Results -- Loss: 0.4415 Acc: 0.3337


Epoch 2 Train -- Loss: 0.4290 Acc: 0.3592
Prev Val Results -- Loss: 0.4415 Acc: 0.3337
0.0014677744750346
Val Results -- Loss: 0.4400 Acc: 0.3360


Epoch 3 Train -- Loss: 0.4331 Acc: 0.3500
Prev Val Results -- Loss: 0.4400 Acc: 0.3360
0.0005834463319510097
Val Results -- Loss: 0.4406 Acc: 0.3361


Epoch 4 Train -- Loss: 0.4241 Acc: 0.3599
Prev Val Results -- Loss: 0.4406 Acc: 0.3361
0.0070903761853181035
Val Results -- Loss: 0.4477 Acc: 0.3349


Epoch 5 Train -- Loss: 0.4242 Acc: 0.3591
Prev Val Results -- Loss: 0.4477 Acc: 0.3349
0.006867700317021552
Val Results -- Loss: 0.4408 Acc: 0.3361


Epoch 6 Train -- Loss: 0.4267 Acc: 0.3532
Prev Val Results -- Loss: 0.4408 Acc: 0.3361
0.005495288413310151
Val Results -- Loss: 0.4463 Acc: 0.3313


Model:  3
Epoch 1 Train -- Loss: 0.1917 Acc: 0.1356
Val Results -- Loss: 0.4410 Acc: 0.3321


Epoch 2 Train -- Loss: 0.4356 Acc: 0.3545
Prev Val Results -- Loss: 0.4410 Acc: 0.3321
0.0009063947437414899
Val Results -- Loss: 0.4419 Acc: 0.3316


Epoch 3 Train -- Loss: 0.4337 Acc: 0.3431
Prev Val Results -- Loss: 0.4419 Acc: 0.3316
0.00045561559240403504
Val Results -- Loss: 0.4424 Acc: 0.3393


Epoch 4 Train -- Loss: 0.4306 Acc: 0.3613
Prev Val Results -- Loss: 0.4424 Acc: 0.3393
0.0004010673103362894
Val Results -- Loss: 0.4428 Acc: 0.3424


Epoch 5 Train -- Loss: 0.4326 Acc: 0.3557
Prev Val Results -- Loss: 0.4428 Acc: 0.3424
0.0025143997798312
Val Results -- Loss: 0.4453 Acc: 0.3291


Model:  4
Epoch 1 Train -- Loss: 0.1924 Acc: 0.1348
Val Results -- Loss: 0.4280 Acc: 0.3424


Epoch 2 Train -- Loss: 0.4251 Acc: 0.3527
Prev Val Results -- Loss: 0.4280 Acc: 0.3424
0.021223040402552518
Val Results -- Loss: 0.4492 Acc: 0.3328


Epoch 3 Train -- Loss: 0.4323 Acc: 0.3592
Prev Val Results -- Loss: 0.4492 Acc: 0.3328
0.00610890285569482
Val Results -- Loss: 0.4431 Acc: 0.3357


Epoch 4 Train -- Loss: 0.4249 Acc: 0.3536
Prev Val Results -- Loss: 0.4431 Acc: 0.3357
0.001948663359153724
Val Results -- Loss: 0.4450 Acc: 0.3273


Epoch 5 Train -- Loss: 0.4288 Acc: 0.3613
Prev Val Results -- Loss: 0.4450 Acc: 0.3273
0.0034112730649020206
Val Results -- Loss: 0.4416 Acc: 0.3325


Model:  5
Epoch 1 Train -- Loss: 0.1928 Acc: 0.1340
Val Results -- Loss: 0.4424 Acc: 0.3319


Epoch 2 Train -- Loss: 0.4385 Acc: 0.3533
Prev Val Results -- Loss: 0.4424 Acc: 0.3319
0.0003832199006298387
Val Results -- Loss: 0.4428 Acc: 0.3380


Epoch 3 Train -- Loss: 0.4337 Acc: 0.3536
Prev Val Results -- Loss: 0.4428 Acc: 0.3380
0.0032131715243599035
Val Results -- Loss: 0.4396 Acc: 0.3389


Epoch 4 Train -- Loss: 0.4252 Acc: 0.3587
Prev Val Results -- Loss: 0.4396 Acc: 0.3389
0.002347074209964939
Val Results -- Loss: 0.4372 Acc: 0.3439


Epoch 5 Train -- Loss: 0.4277 Acc: 0.3540
Prev Val Results -- Loss: 0.4372 Acc: 0.3439
0.005673615761834727
Val Results -- Loss: 0.4429 Acc: 0.3380


Epoch 6 Train -- Loss: 0.4250 Acc: 0.3575
Prev Val Results -- Loss: 0.4429 Acc: 0.3380
0.004709116606854025
Val Results -- Loss: 0.4382 Acc: 0.3453


Model:  6
Epoch 1 Train -- Loss: 0.1923 Acc: 0.1376
Val Results -- Loss: 0.4496 Acc: 0.3275


Epoch 2 Train -- Loss: 0.4214 Acc: 0.3573
Prev Val Results -- Loss: 0.4496 Acc: 0.3275
0.008172373372880903
Val Results -- Loss: 0.4415 Acc: 0.3300


Epoch 3 Train -- Loss: 0.4308 Acc: 0.3540
Prev Val Results -- Loss: 0.4415 Acc: 0.3300
0.001857117511192774
Val Results -- Loss: 0.4433 Acc: 0.3403


Epoch 4 Train -- Loss: 0.4278 Acc: 0.3544
Prev Val Results -- Loss: 0.4433 Acc: 0.3403
0.0026225315712457564
Val Results -- Loss: 0.4459 Acc: 0.3312


Epoch 5 Train -- Loss: 0.4219 Acc: 0.3575
Prev Val Results -- Loss: 0.4459 Acc: 0.3312
8.47109434243265e-05
Val Results -- Loss: 0.4460 Acc: 0.3313


Model:  7
Epoch 1 Train -- Loss: 0.1925 Acc: 0.1341
Val Results -- Loss: 0.4434 Acc: 0.3332


Epoch 2 Train -- Loss: 0.4316 Acc: 0.3587
Prev Val Results -- Loss: 0.4434 Acc: 0.3332
0.002038712229307127
Val Results -- Loss: 0.4454 Acc: 0.3356


Epoch 3 Train -- Loss: 0.4224 Acc: 0.3669
Prev Val Results -- Loss: 0.4454 Acc: 0.3356
0.00031593559816811556
Val Results -- Loss: 0.4451 Acc: 0.3361


Epoch 4 Train -- Loss: 0.4335 Acc: 0.3601
Prev Val Results -- Loss: 0.4451 Acc: 0.3361
0.0064757651632438296
Val Results -- Loss: 0.4386 Acc: 0.3387


Epoch 5 Train -- Loss: 0.4228 Acc: 0.3579
Prev Val Results -- Loss: 0.4386 Acc: 0.3387
0.0049132256646813866
Val Results -- Loss: 0.4435 Acc: 0.3379


Model:  8
Epoch 1 Train -- Loss: 0.1920 Acc: 0.1370
Val Results -- Loss: 0.4413 Acc: 0.3339


Epoch 2 Train -- Loss: 0.4329 Acc: 0.3559
Prev Val Results -- Loss: 0.4413 Acc: 0.3339
0.005628993650899028
Val Results -- Loss: 0.4469 Acc: 0.3340


Epoch 3 Train -- Loss: 0.4204 Acc: 0.3572
Prev Val Results -- Loss: 0.4469 Acc: 0.3340
0.00449449922040196
Val Results -- Loss: 0.4514 Acc: 0.3261


Epoch 4 Train -- Loss: 0.4257 Acc: 0.3597
Prev Val Results -- Loss: 0.4514 Acc: 0.3261
0.004133699455922235
Val Results -- Loss: 0.4473 Acc: 0.3296


Epoch 5 Train -- Loss: 0.4385 Acc: 0.3516
Prev Val Results -- Loss: 0.4473 Acc: 0.3296
0.005941929788124356
Val Results -- Loss: 0.4413 Acc: 0.3363


Epoch 6 Train -- Loss: 0.4298 Acc: 0.3584
Prev Val Results -- Loss: 0.4413 Acc: 0.3363
0.0037617665492336583
Val Results -- Loss: 0.4375 Acc: 0.3428


Model:  9
Epoch 1 Train -- Loss: 0.1927 Acc: 0.1358
Val Results -- Loss: 0.4497 Acc: 0.3344


Epoch 2 Train -- Loss: 0.4309 Acc: 0.3593
Prev Val Results -- Loss: 0.4497 Acc: 0.3344
0.006243650055720695
Val Results -- Loss: 0.4435 Acc: 0.3363


Epoch 3 Train -- Loss: 0.4325 Acc: 0.3547
Prev Val Results -- Loss: 0.4435 Acc: 0.3363
0.0017543207643803682
Val Results -- Loss: 0.4417 Acc: 0.3388


Epoch 4 Train -- Loss: 0.4302 Acc: 0.3552
Prev Val Results -- Loss: 0.4417 Acc: 0.3388
0.0042600203514661095
Val Results -- Loss: 0.4460 Acc: 0.3363


Epoch 5 Train -- Loss: 0.4277 Acc: 0.3564
Prev Val Results -- Loss: 0.4460 Acc: 0.3363
0.0037451432375084637
Val Results -- Loss: 0.4422 Acc: 0.3305


Model:  10
Epoch 1 Train -- Loss: 0.1940 Acc: 0.1342
Val Results -- Loss: 0.4408 Acc: 0.3312


Epoch 2 Train -- Loss: 0.4257 Acc: 0.3571
Prev Val Results -- Loss: 0.4408 Acc: 0.3312
0.004641668350069017
Val Results -- Loss: 0.4455 Acc: 0.3325


Epoch 3 Train -- Loss: 0.4130 Acc: 0.3669
Prev Val Results -- Loss: 0.4455 Acc: 0.3325
0.002929986535497253
Val Results -- Loss: 0.4426 Acc: 0.3375


Epoch 4 Train -- Loss: 0.4362 Acc: 0.3492
Prev Val Results -- Loss: 0.4426 Acc: 0.3375
0.00719787307962011
Val Results -- Loss: 0.4498 Acc: 0.3284


Epoch 5 Train -- Loss: 0.4237 Acc: 0.3607
Prev Val Results -- Loss: 0.4498 Acc: 0.3284
0.0018860003660965963
Val Results -- Loss: 0.4479 Acc: 0.3303


<class 'numpy.ndarray'>
<class 'list'>
['Consolidation', 'Fibrosis', 'Infiltration']
Best Model:  1
Test results -- Loss: 0.4153 Acc: 0.3650
precision: [0.38028169 0.38076546 0.33333333]
recall: [0.378 0.388 0.329]
fscore: [0.37913741 0.38434869 0.33115249]
support: [1000 1000 1000]
Consolidation :  0.5878485
Fibrosis :  0.603298
Infiltration :  0.4956245


Best Model:  2
Test results -- Loss: 0.4278 Acc: 0.3670
precision: [0.39590076 0.38157895 0.32507433]
recall: [0.367 0.406 0.328]
fscore: [0.38090296 0.39341085 0.32653061]
support: [1000 1000 1000]
Consolidation :  0.5892275
Fibrosis :  0.598192
Infiltration :  0.5004915


Best Model:  3
Test results -- Loss: 0.4176 Acc: 0.3647
precision: [0.38787185 0.37209302 0.33777355]
recall: [0.339 0.4   0.355]
fscore: [0.36179296 0.38554217 0.3461726 ]
support: [1000 1000 1000]
Consolidation :  0.59367
Fibrosis :  0.592271
Infiltration :  0.49985050000000003


Best Model:  4
Test results -- Loss: 0.4133 Acc: 0.3693
precision: [0.38232271 0.38638543 0.33841463]
recall: [0.372 0.403 0.333]
fscore: [0.37709072 0.39451787 0.33568548]
support: [1000 1000 1000]
Consolidation :  0.5680725
Fibrosis :  0.581681
Infiltration :  0.4921425


Best Model:  5
Test results -- Loss: 0.4146 Acc: 0.3687
precision: [0.38571429 0.4025974  0.31719368]
recall: [0.351 0.434 0.321]
fscore: [0.36753927 0.41770934 0.31908549]
support: [1000 1000 1000]
Consolidation :  0.5831565
Fibrosis :  0.6042179999999999
Infiltration :  0.49670549999999997


Best Model:  6
Test results -- Loss: 0.4132 Acc: 0.3770
precision: [0.38576349 0.40198735 0.34246575]
recall: [0.336 0.445 0.35 ]
fscore: [0.35916622 0.42240152 0.34619189]
support: [1000 1000 1000]
Consolidation :  0.586799
Fibrosis :  0.6078525
Infiltration :  0.505342


Best Model:  7
Test results -- Loss: 0.4263 Acc: 0.3627
precision: [0.36099138 0.37988281 0.34732824]
recall: [0.335 0.389 0.364]
fscore: [0.34751037 0.38438735 0.35546875]
support: [1000 1000 1000]
Consolidation :  0.5779335
Fibrosis :  0.6066045
Infiltration :  0.520698


Best Model:  8
Test results -- Loss: 0.4186 Acc: 0.3687
precision: [0.38685345 0.38847584 0.33032129]
recall: [0.359 0.418 0.329]
fscore: [0.37240664 0.4026975  0.32965932]
support: [1000 1000 1000]
Consolidation :  0.5853635
Fibrosis :  0.6087225
Infiltration :  0.49690999999999996


Best Model:  9
Test results -- Loss: 0.4349 Acc: 0.3497
precision: [0.38068182 0.36065574 0.3111546 ]
recall: [0.335 0.396 0.318]
fscore: [0.35638298 0.37750238 0.31454006]
support: [1000 1000 1000]
Consolidation :  0.5807334999999999
Fibrosis :  0.5841345
Infiltration :  0.48933550000000003


Best Model:  10
Test results -- Loss: 0.4169 Acc: 0.3740
precision: [0.38606195 0.3898917  0.3451417 ]
recall: [0.349 0.432 0.341]
fscore: [0.36659664 0.40986717 0.34305835]
support: [1000 1000 1000]
Consolidation :  0.5907884999999999
Fibrosis :  0.5897870000000001
Infiltration :  0.500783


Mean AUROC of  Consolidation :  0.58 
 Std AUROC of  Consolidation : 0.01
Mean AUROC of  Fibrosis :  0.6 
 Std AUROC of  Fibrosis : 0.01
Mean AUROC of  Infiltration :  0.5 
 Std AUROC of  Infiltration : 0.01
